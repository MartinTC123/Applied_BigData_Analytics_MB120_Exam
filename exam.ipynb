{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Models import ML_Models\n",
    "exam_models = ML_Models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "import inspect\n",
    "import datetime as dt\n",
    "import numpy as np\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters used for fetching the data from yfinance.\n",
    "start_date = \"2012-01-01\"\n",
    "end_date = dt.date.today()\n",
    "main_col = \"Adj Close\"\n",
    "interval = \"1d\"\n",
    "stocks_list = [\"EQNR.OL\", \"DNB.OL\", \"TEL.OL\", \"NHY.OL\", \"AKRBP.OL\", \"YAR.OL\", \"MOWI.OL\", \"CL=F\", \"OSEBX.OL\"]\n",
    "\n",
    "# Specifying the indicators wanted for further analysis.\n",
    "indicators = [\"MA5\", \"MA20\", \"MA50\", \"MA200\", \"MIN\", \"MAX\", \"LOG_RET\", \"MOM\", \"VOLA\", \"DIFF\"]\n",
    "\n",
    "# Models to utilize for forecasting/prediction.\n",
    "models = [\"LR\", \"DTR\", \"MLP\", \"XGBoost\", \"XGBoost_LR\", \"ADA\", \"GBR\", \"Bagging\", \"StackedRegressor\"]\n",
    "\n",
    "# Metrics used to evaluate the performance of each model.\n",
    "# MAE, MSE, RMSE and MAPE are named with \"neg_\" to be recognized by the cross_validate function from scikit-learn.\n",
    "metric_names = [\"r2\", \"neg_mean_absolute_error\", \"neg_mean_squared_error\", \"neg_root_mean_squared_error\", \"neg_mean_absolute_percentage_error\"]\n",
    "pretty_metric_names = {\"r2\":\"R^2: \", \"neg_mean_absolute_error\":\"MAE: \", \"neg_mean_squared_error\":\"MSE: \",\"neg_root_mean_squared_error\":\"RMSE: \", \"neg_mean_absolute_percentage_error\":\"MAPE: \"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collecting data from Yahoo Finance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading EQNR.OL data\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "Downloading DNB.OL data\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "Downloading TEL.OL data\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "Downloading NHY.OL data\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "Downloading AKRBP.OL data\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "Downloading YAR.OL data\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "Downloading MOWI.OL data\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "Downloading CL=F data\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "Downloading OSEBX.OL data\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "All the data is now downloaded!\n"
     ]
    }
   ],
   "source": [
    "stock_data = {}\n",
    "for ticker in stocks_list:\n",
    "    print(f\"Downloading {ticker} data\")\n",
    "    # fetch stock data from yahoo finance\n",
    "    raw_data = yf.download(ticker, start=start_date, end=end_date, interval=interval)\n",
    "    stock_data[ticker] = raw_data\n",
    "\n",
    "print(\"All the data is now downloaded!\")\n",
    "\n",
    "# Save fetched data to csv\n",
    "for ticker in stocks_list:\n",
    "    #stock_data[ticker].to_csv(\"raw_data/data_\"+ticker+\".csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preproccesing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_indicator_columns(data, indicators):\n",
    "    # Creating label and shifting the selected main_col value by 1.\n",
    "    label_name = \"Label\"\n",
    "    data[label_name] = data[main_col].shift(periods=1)\n",
    "\n",
    "    # Checking which of the different indicators that should be added as a column (based on input from indicators list).\n",
    "    if \"MA5\" in indicators:\n",
    "        data[\"MA5\"] = data[label_name].rolling(5).mean()\n",
    "    if \"MA20\" in indicators:\n",
    "        data[\"MA20\"] = data[label_name].rolling(20).mean()\n",
    "    if \"MA50\" in indicators:\n",
    "        data[\"MA50\"] = data[label_name].rolling(50).mean()\n",
    "    if \"MA200\" in indicators:\n",
    "        data[\"MA200\"] = data[label_name].rolling(200).mean()\n",
    "    if \"MIN\" in indicators:\n",
    "        data[\"MIN\"] = data[label_name].rolling(20).min()\n",
    "    if \"MAX\" in indicators:\n",
    "        data[\"MAX\"] = data[label_name].rolling(20).max()\n",
    "    log_ret = np.log(data[label_name] / data[label_name].shift(1))\n",
    "    if \"LOG_RET\" in indicators:\n",
    "        data[\"LOG_RET\"] = log_ret\n",
    "    if \"MOM\" in indicators:\n",
    "        data[\"MOM\"] = log_ret.rolling(20).mean()\n",
    "    if \"VOLA\" in indicators:\n",
    "        data[\"VOLA\"] = log_ret.rolling(20).std()\n",
    "    if \"DIFF\" in indicators:\n",
    "        data[\"DIFF\"] = data[label_name] - data[label_name].shift(1)\n",
    "\n",
    "    # remove empty vals.\n",
    "    data.dropna(axis=0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_X_y_arrays(data, label_name):\n",
    "        # array that contains the indicators data.\n",
    "        X = data.loc[:, indicators].to_numpy()\n",
    "        # array with the target data (based on main_col).\n",
    "        y = data[label_name].to_numpy()\n",
    "        return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_splits = 5\n",
    "tscv = TimeSeriesSplit(n_splits=n_splits)\n",
    "\n",
    "def create_X_y_train_test_split(X, y, current_stock):\n",
    "    data = stock_data[current_stock]\n",
    "\n",
    "    for train_index, test_index in tscv.split(data):\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pandas/core/arraylike.py:396: RuntimeWarning: invalid value encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "# Adding the specified indicators to the data.\n",
    "for ticker, data in stock_data.items():\n",
    "    add_indicator_columns(data=data, indicators=indicators)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_results = {}\n",
    "trained_models = {}\n",
    "\n",
    "def train_models(input_models):\n",
    "        for ticker, data in stock_data.items():\n",
    "\n",
    "            X, y = create_X_y_arrays(data=data, label_name=\"Label\")\n",
    "\n",
    "            X_train, X_test, y_train, y_test = create_X_y_train_test_split(X=X, y=y, current_stock=ticker)\n",
    "\n",
    "            # Evaluating and training selected models.\n",
    "            for model_i in input_models:\n",
    "                model = exam_models.pick_model(model=model_i)\n",
    "                metric_dict = {}\n",
    "                for metric_name in metric_names:\n",
    "                    metric_dict[metric_name] = metric_name\n",
    "                    \n",
    "                # using method from sci-kit lib to cross-validate\n",
    "                cross_val_results = cross_validate(\n",
    "                    model,\n",
    "                    X,\n",
    "                    y,\n",
    "                    cv=tscv,\n",
    "                    scoring=metric_dict,\n",
    "                    return_train_score=True,\n",
    "                    n_jobs=-1,\n",
    "                    verbose=0  \n",
    "                )\n",
    "                model.fit(X_train, y_train)\n",
    "                cv_results[ticker+\"_model_\"+model_i] = cross_val_results \n",
    "                trained_models[\"trained_model_\"+model_i+\"_\"+ticker] = model\n",
    "\n",
    "        return cv_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "cv_stocks_models = train_models(input_models=models)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting values based on trained models "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "stock_predictions = {}\n",
    "def predict_trained_models(input_models):\n",
    "    for ticker, data in stock_data.items():\n",
    "\n",
    "        # Creating X and y arrays for train and test sets.\n",
    "        X, y = create_X_y_arrays(data=data, label_name= \"Label\")\n",
    "\n",
    "        X_train, X_test, y_train, y_test = create_X_y_train_test_split(X=X, y=y, current_stock=ticker)\n",
    "\n",
    "        last_train_index, last_test_index = None, None\n",
    "\n",
    "        for train_index, test_index in tscv.split(data):\n",
    "            last_train_index, last_test_index = train_index, test_index\n",
    "\n",
    "        prediction = data.loc[data.index[last_test_index], [main_col]].copy(deep=True)\n",
    "        stock_predictions[ticker] = prediction\n",
    "\n",
    "        for model_i in input_models:\n",
    "            model = trained_models[\"trained_model_\"+model_i+\"_\"+ticker]\n",
    "            y_pred = model.predict(X_test)\n",
    "            prediction.loc[:, model_i+\" Prediction\"] = y_pred\n",
    "\n",
    "    return stock_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_stock_data = predict_trained_models(input_models=models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EQNR.OL\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>LR Prediction</th>\n",
       "      <th>DTR Prediction</th>\n",
       "      <th>MLP Prediction</th>\n",
       "      <th>XGBoost Prediction</th>\n",
       "      <th>XGBoost_LR Prediction</th>\n",
       "      <th>ADA Prediction</th>\n",
       "      <th>GBR Prediction</th>\n",
       "      <th>Bagging Prediction</th>\n",
       "      <th>StackedRegressor Prediction</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2021-08-11</th>\n",
       "      <td>177.834885</td>\n",
       "      <td>172.316810</td>\n",
       "      <td>172.243942</td>\n",
       "      <td>172.558017</td>\n",
       "      <td>173.507355</td>\n",
       "      <td>171.043854</td>\n",
       "      <td>172.470428</td>\n",
       "      <td>173.267839</td>\n",
       "      <td>173.068433</td>\n",
       "      <td>172.328178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-08-12</th>\n",
       "      <td>180.592270</td>\n",
       "      <td>176.806584</td>\n",
       "      <td>175.946594</td>\n",
       "      <td>176.924242</td>\n",
       "      <td>175.033615</td>\n",
       "      <td>174.888245</td>\n",
       "      <td>173.154510</td>\n",
       "      <td>176.667954</td>\n",
       "      <td>174.750446</td>\n",
       "      <td>176.703754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-08-13</th>\n",
       "      <td>181.174835</td>\n",
       "      <td>179.059650</td>\n",
       "      <td>175.822571</td>\n",
       "      <td>178.393636</td>\n",
       "      <td>179.794601</td>\n",
       "      <td>177.517609</td>\n",
       "      <td>175.524471</td>\n",
       "      <td>178.579158</td>\n",
       "      <td>179.634190</td>\n",
       "      <td>179.073726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-08-16</th>\n",
       "      <td>178.902863</td>\n",
       "      <td>178.961513</td>\n",
       "      <td>175.822571</td>\n",
       "      <td>178.197804</td>\n",
       "      <td>179.922943</td>\n",
       "      <td>177.458664</td>\n",
       "      <td>175.524471</td>\n",
       "      <td>178.967578</td>\n",
       "      <td>181.096266</td>\n",
       "      <td>178.954194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-08-17</th>\n",
       "      <td>183.330307</td>\n",
       "      <td>178.637226</td>\n",
       "      <td>181.806335</td>\n",
       "      <td>177.326883</td>\n",
       "      <td>181.090668</td>\n",
       "      <td>177.455292</td>\n",
       "      <td>177.672146</td>\n",
       "      <td>178.963687</td>\n",
       "      <td>179.980495</td>\n",
       "      <td>178.631437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-05-02</th>\n",
       "      <td>297.100006</td>\n",
       "      <td>306.968082</td>\n",
       "      <td>189.201675</td>\n",
       "      <td>310.413344</td>\n",
       "      <td>194.206619</td>\n",
       "      <td>292.572083</td>\n",
       "      <td>191.309291</td>\n",
       "      <td>197.213052</td>\n",
       "      <td>192.543054</td>\n",
       "      <td>300.526632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-05-03</th>\n",
       "      <td>293.399994</td>\n",
       "      <td>295.793690</td>\n",
       "      <td>188.859863</td>\n",
       "      <td>297.858180</td>\n",
       "      <td>190.254135</td>\n",
       "      <td>283.107758</td>\n",
       "      <td>190.840377</td>\n",
       "      <td>191.138348</td>\n",
       "      <td>190.492087</td>\n",
       "      <td>289.607508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-05-04</th>\n",
       "      <td>296.149994</td>\n",
       "      <td>295.854591</td>\n",
       "      <td>188.859863</td>\n",
       "      <td>299.263676</td>\n",
       "      <td>189.804108</td>\n",
       "      <td>283.386871</td>\n",
       "      <td>190.840377</td>\n",
       "      <td>191.291655</td>\n",
       "      <td>190.645909</td>\n",
       "      <td>289.692049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-05-05</th>\n",
       "      <td>310.500000</td>\n",
       "      <td>299.235690</td>\n",
       "      <td>188.859863</td>\n",
       "      <td>303.349380</td>\n",
       "      <td>190.501648</td>\n",
       "      <td>286.541412</td>\n",
       "      <td>190.840377</td>\n",
       "      <td>192.103352</td>\n",
       "      <td>191.201379</td>\n",
       "      <td>292.963049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-05-08</th>\n",
       "      <td>314.549988</td>\n",
       "      <td>308.510116</td>\n",
       "      <td>188.859863</td>\n",
       "      <td>313.878763</td>\n",
       "      <td>191.645004</td>\n",
       "      <td>293.409821</td>\n",
       "      <td>191.309291</td>\n",
       "      <td>195.098355</td>\n",
       "      <td>190.022070</td>\n",
       "      <td>301.848456</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>441 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Adj Close  LR Prediction  DTR Prediction  MLP Prediction   \n",
       "Date                                                                    \n",
       "2021-08-11  177.834885     172.316810      172.243942      172.558017  \\\n",
       "2021-08-12  180.592270     176.806584      175.946594      176.924242   \n",
       "2021-08-13  181.174835     179.059650      175.822571      178.393636   \n",
       "2021-08-16  178.902863     178.961513      175.822571      178.197804   \n",
       "2021-08-17  183.330307     178.637226      181.806335      177.326883   \n",
       "...                ...            ...             ...             ...   \n",
       "2023-05-02  297.100006     306.968082      189.201675      310.413344   \n",
       "2023-05-03  293.399994     295.793690      188.859863      297.858180   \n",
       "2023-05-04  296.149994     295.854591      188.859863      299.263676   \n",
       "2023-05-05  310.500000     299.235690      188.859863      303.349380   \n",
       "2023-05-08  314.549988     308.510116      188.859863      313.878763   \n",
       "\n",
       "            XGBoost Prediction  XGBoost_LR Prediction  ADA Prediction   \n",
       "Date                                                                    \n",
       "2021-08-11          173.507355             171.043854      172.470428  \\\n",
       "2021-08-12          175.033615             174.888245      173.154510   \n",
       "2021-08-13          179.794601             177.517609      175.524471   \n",
       "2021-08-16          179.922943             177.458664      175.524471   \n",
       "2021-08-17          181.090668             177.455292      177.672146   \n",
       "...                        ...                    ...             ...   \n",
       "2023-05-02          194.206619             292.572083      191.309291   \n",
       "2023-05-03          190.254135             283.107758      190.840377   \n",
       "2023-05-04          189.804108             283.386871      190.840377   \n",
       "2023-05-05          190.501648             286.541412      190.840377   \n",
       "2023-05-08          191.645004             293.409821      191.309291   \n",
       "\n",
       "            GBR Prediction  Bagging Prediction  StackedRegressor Prediction  \n",
       "Date                                                                         \n",
       "2021-08-11      173.267839          173.068433                   172.328178  \n",
       "2021-08-12      176.667954          174.750446                   176.703754  \n",
       "2021-08-13      178.579158          179.634190                   179.073726  \n",
       "2021-08-16      178.967578          181.096266                   178.954194  \n",
       "2021-08-17      178.963687          179.980495                   178.631437  \n",
       "...                    ...                 ...                          ...  \n",
       "2023-05-02      197.213052          192.543054                   300.526632  \n",
       "2023-05-03      191.138348          190.492087                   289.607508  \n",
       "2023-05-04      191.291655          190.645909                   289.692049  \n",
       "2023-05-05      192.103352          191.201379                   292.963049  \n",
       "2023-05-08      195.098355          190.022070                   301.848456  \n",
       "\n",
       "[441 rows x 10 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DNB.OL\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>LR Prediction</th>\n",
       "      <th>DTR Prediction</th>\n",
       "      <th>MLP Prediction</th>\n",
       "      <th>XGBoost Prediction</th>\n",
       "      <th>XGBoost_LR Prediction</th>\n",
       "      <th>ADA Prediction</th>\n",
       "      <th>GBR Prediction</th>\n",
       "      <th>Bagging Prediction</th>\n",
       "      <th>StackedRegressor Prediction</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2021-06-24</th>\n",
       "      <td>165.566391</td>\n",
       "      <td>165.328389</td>\n",
       "      <td>160.323730</td>\n",
       "      <td>164.723173</td>\n",
       "      <td>159.140671</td>\n",
       "      <td>166.024445</td>\n",
       "      <td>152.813074</td>\n",
       "      <td>159.964588</td>\n",
       "      <td>159.194864</td>\n",
       "      <td>165.298703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-06-25</th>\n",
       "      <td>167.595779</td>\n",
       "      <td>163.058997</td>\n",
       "      <td>160.323730</td>\n",
       "      <td>162.243159</td>\n",
       "      <td>159.400848</td>\n",
       "      <td>163.052368</td>\n",
       "      <td>152.813074</td>\n",
       "      <td>159.157052</td>\n",
       "      <td>159.296333</td>\n",
       "      <td>163.043700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-06-28</th>\n",
       "      <td>163.832916</td>\n",
       "      <td>166.527248</td>\n",
       "      <td>160.323730</td>\n",
       "      <td>165.724866</td>\n",
       "      <td>159.256241</td>\n",
       "      <td>165.322906</td>\n",
       "      <td>152.813074</td>\n",
       "      <td>159.014374</td>\n",
       "      <td>159.194864</td>\n",
       "      <td>166.547620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-06-29</th>\n",
       "      <td>162.353134</td>\n",
       "      <td>163.436365</td>\n",
       "      <td>154.954224</td>\n",
       "      <td>162.098372</td>\n",
       "      <td>156.675751</td>\n",
       "      <td>161.854477</td>\n",
       "      <td>152.813074</td>\n",
       "      <td>156.363562</td>\n",
       "      <td>157.943385</td>\n",
       "      <td>163.368363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-06-30</th>\n",
       "      <td>158.632553</td>\n",
       "      <td>165.053061</td>\n",
       "      <td>157.829224</td>\n",
       "      <td>164.243310</td>\n",
       "      <td>157.786758</td>\n",
       "      <td>162.847305</td>\n",
       "      <td>152.813074</td>\n",
       "      <td>158.157395</td>\n",
       "      <td>157.638971</td>\n",
       "      <td>165.039035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-05-02</th>\n",
       "      <td>187.000000</td>\n",
       "      <td>186.236150</td>\n",
       "      <td>158.970795</td>\n",
       "      <td>186.429129</td>\n",
       "      <td>157.936050</td>\n",
       "      <td>187.960373</td>\n",
       "      <td>152.813074</td>\n",
       "      <td>159.504216</td>\n",
       "      <td>157.638983</td>\n",
       "      <td>186.389280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-05-03</th>\n",
       "      <td>187.750000</td>\n",
       "      <td>184.115197</td>\n",
       "      <td>159.393570</td>\n",
       "      <td>183.943011</td>\n",
       "      <td>158.275589</td>\n",
       "      <td>186.103012</td>\n",
       "      <td>152.813074</td>\n",
       "      <td>158.501943</td>\n",
       "      <td>157.182356</td>\n",
       "      <td>184.303785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-05-04</th>\n",
       "      <td>183.149994</td>\n",
       "      <td>186.713504</td>\n",
       "      <td>158.463409</td>\n",
       "      <td>187.138675</td>\n",
       "      <td>158.029526</td>\n",
       "      <td>187.151611</td>\n",
       "      <td>152.813074</td>\n",
       "      <td>158.703219</td>\n",
       "      <td>157.266920</td>\n",
       "      <td>186.933848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-05-05</th>\n",
       "      <td>185.399994</td>\n",
       "      <td>182.397107</td>\n",
       "      <td>154.954224</td>\n",
       "      <td>182.555183</td>\n",
       "      <td>155.686493</td>\n",
       "      <td>182.693787</td>\n",
       "      <td>152.813074</td>\n",
       "      <td>155.947727</td>\n",
       "      <td>156.484744</td>\n",
       "      <td>182.580838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-05-08</th>\n",
       "      <td>186.199997</td>\n",
       "      <td>186.958204</td>\n",
       "      <td>158.970795</td>\n",
       "      <td>188.169396</td>\n",
       "      <td>157.721115</td>\n",
       "      <td>187.005096</td>\n",
       "      <td>152.813074</td>\n",
       "      <td>158.626004</td>\n",
       "      <td>157.304974</td>\n",
       "      <td>187.223648</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>434 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Adj Close  LR Prediction  DTR Prediction  MLP Prediction   \n",
       "Date                                                                    \n",
       "2021-06-24  165.566391     165.328389      160.323730      164.723173  \\\n",
       "2021-06-25  167.595779     163.058997      160.323730      162.243159   \n",
       "2021-06-28  163.832916     166.527248      160.323730      165.724866   \n",
       "2021-06-29  162.353134     163.436365      154.954224      162.098372   \n",
       "2021-06-30  158.632553     165.053061      157.829224      164.243310   \n",
       "...                ...            ...             ...             ...   \n",
       "2023-05-02  187.000000     186.236150      158.970795      186.429129   \n",
       "2023-05-03  187.750000     184.115197      159.393570      183.943011   \n",
       "2023-05-04  183.149994     186.713504      158.463409      187.138675   \n",
       "2023-05-05  185.399994     182.397107      154.954224      182.555183   \n",
       "2023-05-08  186.199997     186.958204      158.970795      188.169396   \n",
       "\n",
       "            XGBoost Prediction  XGBoost_LR Prediction  ADA Prediction   \n",
       "Date                                                                    \n",
       "2021-06-24          159.140671             166.024445      152.813074  \\\n",
       "2021-06-25          159.400848             163.052368      152.813074   \n",
       "2021-06-28          159.256241             165.322906      152.813074   \n",
       "2021-06-29          156.675751             161.854477      152.813074   \n",
       "2021-06-30          157.786758             162.847305      152.813074   \n",
       "...                        ...                    ...             ...   \n",
       "2023-05-02          157.936050             187.960373      152.813074   \n",
       "2023-05-03          158.275589             186.103012      152.813074   \n",
       "2023-05-04          158.029526             187.151611      152.813074   \n",
       "2023-05-05          155.686493             182.693787      152.813074   \n",
       "2023-05-08          157.721115             187.005096      152.813074   \n",
       "\n",
       "            GBR Prediction  Bagging Prediction  StackedRegressor Prediction  \n",
       "Date                                                                         \n",
       "2021-06-24      159.964588          159.194864                   165.298703  \n",
       "2021-06-25      159.157052          159.296333                   163.043700  \n",
       "2021-06-28      159.014374          159.194864                   166.547620  \n",
       "2021-06-29      156.363562          157.943385                   163.368363  \n",
       "2021-06-30      158.157395          157.638971                   165.039035  \n",
       "...                    ...                 ...                          ...  \n",
       "2023-05-02      159.504216          157.638983                   186.389280  \n",
       "2023-05-03      158.501943          157.182356                   184.303785  \n",
       "2023-05-04      158.703219          157.266920                   186.933848  \n",
       "2023-05-05      155.947727          156.484744                   182.580838  \n",
       "2023-05-08      158.626004          157.304974                   187.223648  \n",
       "\n",
       "[434 rows x 10 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEL.OL\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>LR Prediction</th>\n",
       "      <th>DTR Prediction</th>\n",
       "      <th>MLP Prediction</th>\n",
       "      <th>XGBoost Prediction</th>\n",
       "      <th>XGBoost_LR Prediction</th>\n",
       "      <th>ADA Prediction</th>\n",
       "      <th>GBR Prediction</th>\n",
       "      <th>Bagging Prediction</th>\n",
       "      <th>StackedRegressor Prediction</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2021-08-11</th>\n",
       "      <td>138.361984</td>\n",
       "      <td>137.873184</td>\n",
       "      <td>138.050247</td>\n",
       "      <td>138.468653</td>\n",
       "      <td>138.390823</td>\n",
       "      <td>136.622070</td>\n",
       "      <td>137.706387</td>\n",
       "      <td>138.552091</td>\n",
       "      <td>138.005714</td>\n",
       "      <td>137.900198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-08-12</th>\n",
       "      <td>139.742477</td>\n",
       "      <td>137.480174</td>\n",
       "      <td>138.094788</td>\n",
       "      <td>138.047500</td>\n",
       "      <td>137.512527</td>\n",
       "      <td>136.486725</td>\n",
       "      <td>137.706387</td>\n",
       "      <td>138.297336</td>\n",
       "      <td>137.649448</td>\n",
       "      <td>137.488337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-08-13</th>\n",
       "      <td>140.321396</td>\n",
       "      <td>138.849854</td>\n",
       "      <td>138.629150</td>\n",
       "      <td>139.609270</td>\n",
       "      <td>139.386292</td>\n",
       "      <td>137.830566</td>\n",
       "      <td>138.433800</td>\n",
       "      <td>139.567254</td>\n",
       "      <td>138.433864</td>\n",
       "      <td>138.879376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-08-16</th>\n",
       "      <td>140.232315</td>\n",
       "      <td>138.863133</td>\n",
       "      <td>138.629150</td>\n",
       "      <td>139.534716</td>\n",
       "      <td>139.125671</td>\n",
       "      <td>137.798981</td>\n",
       "      <td>138.433800</td>\n",
       "      <td>139.419476</td>\n",
       "      <td>138.536288</td>\n",
       "      <td>138.883012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-08-17</th>\n",
       "      <td>141.033920</td>\n",
       "      <td>139.633103</td>\n",
       "      <td>140.291122</td>\n",
       "      <td>139.616004</td>\n",
       "      <td>140.355896</td>\n",
       "      <td>139.556335</td>\n",
       "      <td>139.412972</td>\n",
       "      <td>140.723853</td>\n",
       "      <td>140.945033</td>\n",
       "      <td>139.642126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-05-02</th>\n",
       "      <td>131.149994</td>\n",
       "      <td>131.680164</td>\n",
       "      <td>133.152939</td>\n",
       "      <td>131.146849</td>\n",
       "      <td>132.885223</td>\n",
       "      <td>132.582581</td>\n",
       "      <td>131.291136</td>\n",
       "      <td>132.142713</td>\n",
       "      <td>131.211269</td>\n",
       "      <td>131.697763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-05-03</th>\n",
       "      <td>130.949997</td>\n",
       "      <td>131.197236</td>\n",
       "      <td>133.152939</td>\n",
       "      <td>130.986670</td>\n",
       "      <td>131.670578</td>\n",
       "      <td>131.756424</td>\n",
       "      <td>131.291136</td>\n",
       "      <td>131.688021</td>\n",
       "      <td>131.555347</td>\n",
       "      <td>131.210266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-05-04</th>\n",
       "      <td>128.399994</td>\n",
       "      <td>132.244930</td>\n",
       "      <td>133.152939</td>\n",
       "      <td>132.382524</td>\n",
       "      <td>132.080566</td>\n",
       "      <td>132.598557</td>\n",
       "      <td>131.291136</td>\n",
       "      <td>132.316567</td>\n",
       "      <td>132.691180</td>\n",
       "      <td>132.262270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-05-05</th>\n",
       "      <td>128.000000</td>\n",
       "      <td>129.618837</td>\n",
       "      <td>128.982056</td>\n",
       "      <td>130.018589</td>\n",
       "      <td>127.983070</td>\n",
       "      <td>130.509949</td>\n",
       "      <td>131.270207</td>\n",
       "      <td>130.240275</td>\n",
       "      <td>129.723573</td>\n",
       "      <td>129.617354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-05-08</th>\n",
       "      <td>129.449997</td>\n",
       "      <td>130.113153</td>\n",
       "      <td>130.594315</td>\n",
       "      <td>130.879141</td>\n",
       "      <td>129.537155</td>\n",
       "      <td>132.012100</td>\n",
       "      <td>129.267701</td>\n",
       "      <td>129.560273</td>\n",
       "      <td>129.253156</td>\n",
       "      <td>130.137620</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>441 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Adj Close  LR Prediction  DTR Prediction  MLP Prediction   \n",
       "Date                                                                    \n",
       "2021-08-11  138.361984     137.873184      138.050247      138.468653  \\\n",
       "2021-08-12  139.742477     137.480174      138.094788      138.047500   \n",
       "2021-08-13  140.321396     138.849854      138.629150      139.609270   \n",
       "2021-08-16  140.232315     138.863133      138.629150      139.534716   \n",
       "2021-08-17  141.033920     139.633103      140.291122      139.616004   \n",
       "...                ...            ...             ...             ...   \n",
       "2023-05-02  131.149994     131.680164      133.152939      131.146849   \n",
       "2023-05-03  130.949997     131.197236      133.152939      130.986670   \n",
       "2023-05-04  128.399994     132.244930      133.152939      132.382524   \n",
       "2023-05-05  128.000000     129.618837      128.982056      130.018589   \n",
       "2023-05-08  129.449997     130.113153      130.594315      130.879141   \n",
       "\n",
       "            XGBoost Prediction  XGBoost_LR Prediction  ADA Prediction   \n",
       "Date                                                                    \n",
       "2021-08-11          138.390823             136.622070      137.706387  \\\n",
       "2021-08-12          137.512527             136.486725      137.706387   \n",
       "2021-08-13          139.386292             137.830566      138.433800   \n",
       "2021-08-16          139.125671             137.798981      138.433800   \n",
       "2021-08-17          140.355896             139.556335      139.412972   \n",
       "...                        ...                    ...             ...   \n",
       "2023-05-02          132.885223             132.582581      131.291136   \n",
       "2023-05-03          131.670578             131.756424      131.291136   \n",
       "2023-05-04          132.080566             132.598557      131.291136   \n",
       "2023-05-05          127.983070             130.509949      131.270207   \n",
       "2023-05-08          129.537155             132.012100      129.267701   \n",
       "\n",
       "            GBR Prediction  Bagging Prediction  StackedRegressor Prediction  \n",
       "Date                                                                         \n",
       "2021-08-11      138.552091          138.005714                   137.900198  \n",
       "2021-08-12      138.297336          137.649448                   137.488337  \n",
       "2021-08-13      139.567254          138.433864                   138.879376  \n",
       "2021-08-16      139.419476          138.536288                   138.883012  \n",
       "2021-08-17      140.723853          140.945033                   139.642126  \n",
       "...                    ...                 ...                          ...  \n",
       "2023-05-02      132.142713          131.211269                   131.697763  \n",
       "2023-05-03      131.688021          131.555347                   131.210266  \n",
       "2023-05-04      132.316567          132.691180                   132.262270  \n",
       "2023-05-05      130.240275          129.723573                   129.617354  \n",
       "2023-05-08      129.560273          129.253156                   130.137620  \n",
       "\n",
       "[441 rows x 10 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NHY.OL\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>LR Prediction</th>\n",
       "      <th>DTR Prediction</th>\n",
       "      <th>MLP Prediction</th>\n",
       "      <th>XGBoost Prediction</th>\n",
       "      <th>XGBoost_LR Prediction</th>\n",
       "      <th>ADA Prediction</th>\n",
       "      <th>GBR Prediction</th>\n",
       "      <th>Bagging Prediction</th>\n",
       "      <th>StackedRegressor Prediction</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2021-08-11</th>\n",
       "      <td>57.671207</td>\n",
       "      <td>56.449810</td>\n",
       "      <td>55.268242</td>\n",
       "      <td>57.274044</td>\n",
       "      <td>54.604717</td>\n",
       "      <td>56.003208</td>\n",
       "      <td>54.251952</td>\n",
       "      <td>55.566545</td>\n",
       "      <td>55.258783</td>\n",
       "      <td>56.550199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-08-12</th>\n",
       "      <td>58.352367</td>\n",
       "      <td>56.561751</td>\n",
       "      <td>55.268242</td>\n",
       "      <td>57.322797</td>\n",
       "      <td>55.257801</td>\n",
       "      <td>56.225105</td>\n",
       "      <td>54.251952</td>\n",
       "      <td>55.642682</td>\n",
       "      <td>55.258783</td>\n",
       "      <td>56.675306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-08-13</th>\n",
       "      <td>59.128128</td>\n",
       "      <td>56.886879</td>\n",
       "      <td>55.268242</td>\n",
       "      <td>57.637277</td>\n",
       "      <td>55.271454</td>\n",
       "      <td>56.223598</td>\n",
       "      <td>54.251952</td>\n",
       "      <td>56.121442</td>\n",
       "      <td>55.149040</td>\n",
       "      <td>57.005703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-08-16</th>\n",
       "      <td>57.936108</td>\n",
       "      <td>57.886797</td>\n",
       "      <td>55.268242</td>\n",
       "      <td>58.536764</td>\n",
       "      <td>55.137451</td>\n",
       "      <td>57.261105</td>\n",
       "      <td>54.251952</td>\n",
       "      <td>55.551077</td>\n",
       "      <td>55.258783</td>\n",
       "      <td>58.040326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-08-17</th>\n",
       "      <td>58.030708</td>\n",
       "      <td>57.300024</td>\n",
       "      <td>54.662773</td>\n",
       "      <td>57.768235</td>\n",
       "      <td>54.932076</td>\n",
       "      <td>56.984867</td>\n",
       "      <td>54.251952</td>\n",
       "      <td>54.696941</td>\n",
       "      <td>54.944693</td>\n",
       "      <td>57.435980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-05-02</th>\n",
       "      <td>76.559998</td>\n",
       "      <td>77.581132</td>\n",
       "      <td>54.662773</td>\n",
       "      <td>78.530051</td>\n",
       "      <td>54.941650</td>\n",
       "      <td>77.121475</td>\n",
       "      <td>54.186403</td>\n",
       "      <td>54.222608</td>\n",
       "      <td>54.946585</td>\n",
       "      <td>78.427053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-05-03</th>\n",
       "      <td>76.720001</td>\n",
       "      <td>77.153240</td>\n",
       "      <td>54.662773</td>\n",
       "      <td>78.156330</td>\n",
       "      <td>54.089603</td>\n",
       "      <td>77.070404</td>\n",
       "      <td>54.186403</td>\n",
       "      <td>53.501294</td>\n",
       "      <td>54.946585</td>\n",
       "      <td>77.986674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-05-04</th>\n",
       "      <td>74.940002</td>\n",
       "      <td>78.202233</td>\n",
       "      <td>54.662773</td>\n",
       "      <td>79.223090</td>\n",
       "      <td>54.486225</td>\n",
       "      <td>77.861671</td>\n",
       "      <td>54.186403</td>\n",
       "      <td>53.935568</td>\n",
       "      <td>55.048759</td>\n",
       "      <td>79.076187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-05-05</th>\n",
       "      <td>73.160004</td>\n",
       "      <td>75.755017</td>\n",
       "      <td>54.662773</td>\n",
       "      <td>76.913445</td>\n",
       "      <td>53.965084</td>\n",
       "      <td>75.872658</td>\n",
       "      <td>54.186403</td>\n",
       "      <td>53.154433</td>\n",
       "      <td>54.946585</td>\n",
       "      <td>76.552769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-05-08</th>\n",
       "      <td>75.080002</td>\n",
       "      <td>74.022178</td>\n",
       "      <td>54.662773</td>\n",
       "      <td>75.393550</td>\n",
       "      <td>54.083847</td>\n",
       "      <td>74.525444</td>\n",
       "      <td>54.186403</td>\n",
       "      <td>52.955791</td>\n",
       "      <td>54.946585</td>\n",
       "      <td>74.778625</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>441 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Adj Close  LR Prediction  DTR Prediction  MLP Prediction   \n",
       "Date                                                                   \n",
       "2021-08-11  57.671207      56.449810       55.268242       57.274044  \\\n",
       "2021-08-12  58.352367      56.561751       55.268242       57.322797   \n",
       "2021-08-13  59.128128      56.886879       55.268242       57.637277   \n",
       "2021-08-16  57.936108      57.886797       55.268242       58.536764   \n",
       "2021-08-17  58.030708      57.300024       54.662773       57.768235   \n",
       "...               ...            ...             ...             ...   \n",
       "2023-05-02  76.559998      77.581132       54.662773       78.530051   \n",
       "2023-05-03  76.720001      77.153240       54.662773       78.156330   \n",
       "2023-05-04  74.940002      78.202233       54.662773       79.223090   \n",
       "2023-05-05  73.160004      75.755017       54.662773       76.913445   \n",
       "2023-05-08  75.080002      74.022178       54.662773       75.393550   \n",
       "\n",
       "            XGBoost Prediction  XGBoost_LR Prediction  ADA Prediction   \n",
       "Date                                                                    \n",
       "2021-08-11           54.604717              56.003208       54.251952  \\\n",
       "2021-08-12           55.257801              56.225105       54.251952   \n",
       "2021-08-13           55.271454              56.223598       54.251952   \n",
       "2021-08-16           55.137451              57.261105       54.251952   \n",
       "2021-08-17           54.932076              56.984867       54.251952   \n",
       "...                        ...                    ...             ...   \n",
       "2023-05-02           54.941650              77.121475       54.186403   \n",
       "2023-05-03           54.089603              77.070404       54.186403   \n",
       "2023-05-04           54.486225              77.861671       54.186403   \n",
       "2023-05-05           53.965084              75.872658       54.186403   \n",
       "2023-05-08           54.083847              74.525444       54.186403   \n",
       "\n",
       "            GBR Prediction  Bagging Prediction  StackedRegressor Prediction  \n",
       "Date                                                                         \n",
       "2021-08-11       55.566545           55.258783                    56.550199  \n",
       "2021-08-12       55.642682           55.258783                    56.675306  \n",
       "2021-08-13       56.121442           55.149040                    57.005703  \n",
       "2021-08-16       55.551077           55.258783                    58.040326  \n",
       "2021-08-17       54.696941           54.944693                    57.435980  \n",
       "...                    ...                 ...                          ...  \n",
       "2023-05-02       54.222608           54.946585                    78.427053  \n",
       "2023-05-03       53.501294           54.946585                    77.986674  \n",
       "2023-05-04       53.935568           55.048759                    79.076187  \n",
       "2023-05-05       53.154433           54.946585                    76.552769  \n",
       "2023-05-08       52.955791           54.946585                    74.778625  \n",
       "\n",
       "[441 rows x 10 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AKRBP.OL\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>LR Prediction</th>\n",
       "      <th>DTR Prediction</th>\n",
       "      <th>MLP Prediction</th>\n",
       "      <th>XGBoost Prediction</th>\n",
       "      <th>XGBoost_LR Prediction</th>\n",
       "      <th>ADA Prediction</th>\n",
       "      <th>GBR Prediction</th>\n",
       "      <th>Bagging Prediction</th>\n",
       "      <th>StackedRegressor Prediction</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2021-08-11</th>\n",
       "      <td>210.668625</td>\n",
       "      <td>216.053991</td>\n",
       "      <td>213.334213</td>\n",
       "      <td>213.054088</td>\n",
       "      <td>213.633575</td>\n",
       "      <td>214.703751</td>\n",
       "      <td>212.458634</td>\n",
       "      <td>213.751332</td>\n",
       "      <td>214.059868</td>\n",
       "      <td>215.460706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-08-12</th>\n",
       "      <td>212.356827</td>\n",
       "      <td>210.394461</td>\n",
       "      <td>212.139908</td>\n",
       "      <td>208.182312</td>\n",
       "      <td>211.639908</td>\n",
       "      <td>206.720642</td>\n",
       "      <td>212.458634</td>\n",
       "      <td>209.891843</td>\n",
       "      <td>212.488251</td>\n",
       "      <td>210.110607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-08-13</th>\n",
       "      <td>210.846359</td>\n",
       "      <td>213.956727</td>\n",
       "      <td>213.334213</td>\n",
       "      <td>211.566937</td>\n",
       "      <td>213.321884</td>\n",
       "      <td>211.526886</td>\n",
       "      <td>212.458634</td>\n",
       "      <td>212.125203</td>\n",
       "      <td>215.065237</td>\n",
       "      <td>213.592396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-08-16</th>\n",
       "      <td>206.137161</td>\n",
       "      <td>211.226714</td>\n",
       "      <td>212.139908</td>\n",
       "      <td>208.648884</td>\n",
       "      <td>211.942749</td>\n",
       "      <td>209.359222</td>\n",
       "      <td>212.362988</td>\n",
       "      <td>210.493391</td>\n",
       "      <td>212.385635</td>\n",
       "      <td>210.857300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-08-17</th>\n",
       "      <td>208.713882</td>\n",
       "      <td>207.504736</td>\n",
       "      <td>205.927261</td>\n",
       "      <td>204.968069</td>\n",
       "      <td>211.425201</td>\n",
       "      <td>206.220093</td>\n",
       "      <td>208.701904</td>\n",
       "      <td>208.261489</td>\n",
       "      <td>205.404619</td>\n",
       "      <td>207.204898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-05-02</th>\n",
       "      <td>234.464951</td>\n",
       "      <td>249.296814</td>\n",
       "      <td>233.926163</td>\n",
       "      <td>248.566913</td>\n",
       "      <td>232.453751</td>\n",
       "      <td>255.086197</td>\n",
       "      <td>241.195852</td>\n",
       "      <td>239.557686</td>\n",
       "      <td>237.979761</td>\n",
       "      <td>248.472016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-05-03</th>\n",
       "      <td>236.199997</td>\n",
       "      <td>230.805601</td>\n",
       "      <td>229.094803</td>\n",
       "      <td>229.978605</td>\n",
       "      <td>221.337692</td>\n",
       "      <td>235.399292</td>\n",
       "      <td>240.171487</td>\n",
       "      <td>225.867751</td>\n",
       "      <td>229.406078</td>\n",
       "      <td>230.436299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-05-04</th>\n",
       "      <td>235.800003</td>\n",
       "      <td>240.521664</td>\n",
       "      <td>233.926163</td>\n",
       "      <td>239.965835</td>\n",
       "      <td>223.259186</td>\n",
       "      <td>247.002808</td>\n",
       "      <td>240.171487</td>\n",
       "      <td>232.637075</td>\n",
       "      <td>231.946730</td>\n",
       "      <td>239.850520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-05-05</th>\n",
       "      <td>241.300003</td>\n",
       "      <td>238.451204</td>\n",
       "      <td>233.926163</td>\n",
       "      <td>237.786943</td>\n",
       "      <td>223.651123</td>\n",
       "      <td>244.567963</td>\n",
       "      <td>240.171487</td>\n",
       "      <td>231.157178</td>\n",
       "      <td>232.641533</td>\n",
       "      <td>237.861789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-05-08</th>\n",
       "      <td>246.500000</td>\n",
       "      <td>242.683077</td>\n",
       "      <td>233.926163</td>\n",
       "      <td>242.298358</td>\n",
       "      <td>226.997543</td>\n",
       "      <td>246.809891</td>\n",
       "      <td>240.171487</td>\n",
       "      <td>232.887723</td>\n",
       "      <td>231.833382</td>\n",
       "      <td>242.096668</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>441 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Adj Close  LR Prediction  DTR Prediction  MLP Prediction   \n",
       "Date                                                                    \n",
       "2021-08-11  210.668625     216.053991      213.334213      213.054088  \\\n",
       "2021-08-12  212.356827     210.394461      212.139908      208.182312   \n",
       "2021-08-13  210.846359     213.956727      213.334213      211.566937   \n",
       "2021-08-16  206.137161     211.226714      212.139908      208.648884   \n",
       "2021-08-17  208.713882     207.504736      205.927261      204.968069   \n",
       "...                ...            ...             ...             ...   \n",
       "2023-05-02  234.464951     249.296814      233.926163      248.566913   \n",
       "2023-05-03  236.199997     230.805601      229.094803      229.978605   \n",
       "2023-05-04  235.800003     240.521664      233.926163      239.965835   \n",
       "2023-05-05  241.300003     238.451204      233.926163      237.786943   \n",
       "2023-05-08  246.500000     242.683077      233.926163      242.298358   \n",
       "\n",
       "            XGBoost Prediction  XGBoost_LR Prediction  ADA Prediction   \n",
       "Date                                                                    \n",
       "2021-08-11          213.633575             214.703751      212.458634  \\\n",
       "2021-08-12          211.639908             206.720642      212.458634   \n",
       "2021-08-13          213.321884             211.526886      212.458634   \n",
       "2021-08-16          211.942749             209.359222      212.362988   \n",
       "2021-08-17          211.425201             206.220093      208.701904   \n",
       "...                        ...                    ...             ...   \n",
       "2023-05-02          232.453751             255.086197      241.195852   \n",
       "2023-05-03          221.337692             235.399292      240.171487   \n",
       "2023-05-04          223.259186             247.002808      240.171487   \n",
       "2023-05-05          223.651123             244.567963      240.171487   \n",
       "2023-05-08          226.997543             246.809891      240.171487   \n",
       "\n",
       "            GBR Prediction  Bagging Prediction  StackedRegressor Prediction  \n",
       "Date                                                                         \n",
       "2021-08-11      213.751332          214.059868                   215.460706  \n",
       "2021-08-12      209.891843          212.488251                   210.110607  \n",
       "2021-08-13      212.125203          215.065237                   213.592396  \n",
       "2021-08-16      210.493391          212.385635                   210.857300  \n",
       "2021-08-17      208.261489          205.404619                   207.204898  \n",
       "...                    ...                 ...                          ...  \n",
       "2023-05-02      239.557686          237.979761                   248.472016  \n",
       "2023-05-03      225.867751          229.406078                   230.436299  \n",
       "2023-05-04      232.637075          231.946730                   239.850520  \n",
       "2023-05-05      231.157178          232.641533                   237.861789  \n",
       "2023-05-08      232.887723          231.833382                   242.096668  \n",
       "\n",
       "[441 rows x 10 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YAR.OL\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>LR Prediction</th>\n",
       "      <th>DTR Prediction</th>\n",
       "      <th>MLP Prediction</th>\n",
       "      <th>XGBoost Prediction</th>\n",
       "      <th>XGBoost_LR Prediction</th>\n",
       "      <th>ADA Prediction</th>\n",
       "      <th>GBR Prediction</th>\n",
       "      <th>Bagging Prediction</th>\n",
       "      <th>StackedRegressor Prediction</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2021-08-11</th>\n",
       "      <td>389.759003</td>\n",
       "      <td>395.647485</td>\n",
       "      <td>388.977570</td>\n",
       "      <td>403.094027</td>\n",
       "      <td>380.417389</td>\n",
       "      <td>396.017090</td>\n",
       "      <td>392.206429</td>\n",
       "      <td>391.141631</td>\n",
       "      <td>388.508710</td>\n",
       "      <td>395.923667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-08-12</th>\n",
       "      <td>389.498505</td>\n",
       "      <td>390.107836</td>\n",
       "      <td>390.193115</td>\n",
       "      <td>397.432585</td>\n",
       "      <td>377.838593</td>\n",
       "      <td>390.496613</td>\n",
       "      <td>392.206429</td>\n",
       "      <td>388.124353</td>\n",
       "      <td>388.873373</td>\n",
       "      <td>390.415869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-08-13</th>\n",
       "      <td>391.756012</td>\n",
       "      <td>387.710175</td>\n",
       "      <td>390.193115</td>\n",
       "      <td>395.460529</td>\n",
       "      <td>377.713898</td>\n",
       "      <td>385.855316</td>\n",
       "      <td>391.920996</td>\n",
       "      <td>389.031594</td>\n",
       "      <td>388.986249</td>\n",
       "      <td>388.054579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-08-16</th>\n",
       "      <td>395.923584</td>\n",
       "      <td>392.081937</td>\n",
       "      <td>390.193115</td>\n",
       "      <td>398.098472</td>\n",
       "      <td>390.187653</td>\n",
       "      <td>393.140015</td>\n",
       "      <td>393.752958</td>\n",
       "      <td>391.508683</td>\n",
       "      <td>390.193121</td>\n",
       "      <td>391.800523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-08-17</th>\n",
       "      <td>389.064392</td>\n",
       "      <td>395.536572</td>\n",
       "      <td>390.193115</td>\n",
       "      <td>400.601868</td>\n",
       "      <td>392.220947</td>\n",
       "      <td>396.671936</td>\n",
       "      <td>398.462260</td>\n",
       "      <td>392.684391</td>\n",
       "      <td>390.549106</td>\n",
       "      <td>395.202034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-05-02</th>\n",
       "      <td>429.299988</td>\n",
       "      <td>428.215703</td>\n",
       "      <td>408.773712</td>\n",
       "      <td>433.208894</td>\n",
       "      <td>405.930695</td>\n",
       "      <td>425.851868</td>\n",
       "      <td>412.703537</td>\n",
       "      <td>404.623276</td>\n",
       "      <td>411.222217</td>\n",
       "      <td>428.044852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-05-03</th>\n",
       "      <td>431.799988</td>\n",
       "      <td>437.849055</td>\n",
       "      <td>410.076111</td>\n",
       "      <td>444.821516</td>\n",
       "      <td>407.346008</td>\n",
       "      <td>435.882355</td>\n",
       "      <td>412.703537</td>\n",
       "      <td>412.457649</td>\n",
       "      <td>418.133514</td>\n",
       "      <td>438.054083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-05-04</th>\n",
       "      <td>427.000000</td>\n",
       "      <td>437.423079</td>\n",
       "      <td>410.076111</td>\n",
       "      <td>444.520047</td>\n",
       "      <td>409.977875</td>\n",
       "      <td>435.788055</td>\n",
       "      <td>412.703537</td>\n",
       "      <td>415.624534</td>\n",
       "      <td>417.829626</td>\n",
       "      <td>437.678713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-05-05</th>\n",
       "      <td>431.899994</td>\n",
       "      <td>428.441205</td>\n",
       "      <td>403.216919</td>\n",
       "      <td>435.560710</td>\n",
       "      <td>405.546967</td>\n",
       "      <td>428.867371</td>\n",
       "      <td>412.703537</td>\n",
       "      <td>408.100052</td>\n",
       "      <td>410.458154</td>\n",
       "      <td>428.656426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-05-08</th>\n",
       "      <td>429.600006</td>\n",
       "      <td>433.157920</td>\n",
       "      <td>410.076111</td>\n",
       "      <td>440.588508</td>\n",
       "      <td>409.966064</td>\n",
       "      <td>434.523712</td>\n",
       "      <td>412.703537</td>\n",
       "      <td>416.175803</td>\n",
       "      <td>419.192786</td>\n",
       "      <td>433.508299</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>441 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Adj Close  LR Prediction  DTR Prediction  MLP Prediction   \n",
       "Date                                                                    \n",
       "2021-08-11  389.759003     395.647485      388.977570      403.094027  \\\n",
       "2021-08-12  389.498505     390.107836      390.193115      397.432585   \n",
       "2021-08-13  391.756012     387.710175      390.193115      395.460529   \n",
       "2021-08-16  395.923584     392.081937      390.193115      398.098472   \n",
       "2021-08-17  389.064392     395.536572      390.193115      400.601868   \n",
       "...                ...            ...             ...             ...   \n",
       "2023-05-02  429.299988     428.215703      408.773712      433.208894   \n",
       "2023-05-03  431.799988     437.849055      410.076111      444.821516   \n",
       "2023-05-04  427.000000     437.423079      410.076111      444.520047   \n",
       "2023-05-05  431.899994     428.441205      403.216919      435.560710   \n",
       "2023-05-08  429.600006     433.157920      410.076111      440.588508   \n",
       "\n",
       "            XGBoost Prediction  XGBoost_LR Prediction  ADA Prediction   \n",
       "Date                                                                    \n",
       "2021-08-11          380.417389             396.017090      392.206429  \\\n",
       "2021-08-12          377.838593             390.496613      392.206429   \n",
       "2021-08-13          377.713898             385.855316      391.920996   \n",
       "2021-08-16          390.187653             393.140015      393.752958   \n",
       "2021-08-17          392.220947             396.671936      398.462260   \n",
       "...                        ...                    ...             ...   \n",
       "2023-05-02          405.930695             425.851868      412.703537   \n",
       "2023-05-03          407.346008             435.882355      412.703537   \n",
       "2023-05-04          409.977875             435.788055      412.703537   \n",
       "2023-05-05          405.546967             428.867371      412.703537   \n",
       "2023-05-08          409.966064             434.523712      412.703537   \n",
       "\n",
       "            GBR Prediction  Bagging Prediction  StackedRegressor Prediction  \n",
       "Date                                                                         \n",
       "2021-08-11      391.141631          388.508710                   395.923667  \n",
       "2021-08-12      388.124353          388.873373                   390.415869  \n",
       "2021-08-13      389.031594          388.986249                   388.054579  \n",
       "2021-08-16      391.508683          390.193121                   391.800523  \n",
       "2021-08-17      392.684391          390.549106                   395.202034  \n",
       "...                    ...                 ...                          ...  \n",
       "2023-05-02      404.623276          411.222217                   428.044852  \n",
       "2023-05-03      412.457649          418.133514                   438.054083  \n",
       "2023-05-04      415.624534          417.829626                   437.678713  \n",
       "2023-05-05      408.100052          410.458154                   428.656426  \n",
       "2023-05-08      416.175803          419.192786                   433.508299  \n",
       "\n",
       "[441 rows x 10 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MOWI.OL\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>LR Prediction</th>\n",
       "      <th>DTR Prediction</th>\n",
       "      <th>MLP Prediction</th>\n",
       "      <th>XGBoost Prediction</th>\n",
       "      <th>XGBoost_LR Prediction</th>\n",
       "      <th>ADA Prediction</th>\n",
       "      <th>GBR Prediction</th>\n",
       "      <th>Bagging Prediction</th>\n",
       "      <th>StackedRegressor Prediction</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2021-08-11</th>\n",
       "      <td>215.904449</td>\n",
       "      <td>219.277143</td>\n",
       "      <td>216.575272</td>\n",
       "      <td>217.405019</td>\n",
       "      <td>217.550354</td>\n",
       "      <td>218.676453</td>\n",
       "      <td>214.635613</td>\n",
       "      <td>218.417178</td>\n",
       "      <td>217.868967</td>\n",
       "      <td>219.263354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-08-12</th>\n",
       "      <td>216.287766</td>\n",
       "      <td>217.267966</td>\n",
       "      <td>214.121323</td>\n",
       "      <td>215.149052</td>\n",
       "      <td>218.125473</td>\n",
       "      <td>217.685043</td>\n",
       "      <td>214.635613</td>\n",
       "      <td>217.241738</td>\n",
       "      <td>217.916881</td>\n",
       "      <td>217.168788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-08-13</th>\n",
       "      <td>217.054398</td>\n",
       "      <td>217.417704</td>\n",
       "      <td>217.246063</td>\n",
       "      <td>215.884530</td>\n",
       "      <td>216.535248</td>\n",
       "      <td>217.933319</td>\n",
       "      <td>214.635613</td>\n",
       "      <td>216.451197</td>\n",
       "      <td>216.517520</td>\n",
       "      <td>217.367880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-08-16</th>\n",
       "      <td>216.958542</td>\n",
       "      <td>217.590599</td>\n",
       "      <td>217.246063</td>\n",
       "      <td>216.133840</td>\n",
       "      <td>216.325745</td>\n",
       "      <td>218.288147</td>\n",
       "      <td>214.635613</td>\n",
       "      <td>216.690617</td>\n",
       "      <td>216.564281</td>\n",
       "      <td>217.537270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-08-17</th>\n",
       "      <td>216.096130</td>\n",
       "      <td>218.028584</td>\n",
       "      <td>217.246063</td>\n",
       "      <td>215.662954</td>\n",
       "      <td>215.928650</td>\n",
       "      <td>218.767090</td>\n",
       "      <td>214.635613</td>\n",
       "      <td>216.505656</td>\n",
       "      <td>216.790698</td>\n",
       "      <td>217.997600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-05-02</th>\n",
       "      <td>201.600006</td>\n",
       "      <td>201.056443</td>\n",
       "      <td>201.276337</td>\n",
       "      <td>202.359313</td>\n",
       "      <td>200.872910</td>\n",
       "      <td>201.411545</td>\n",
       "      <td>197.779186</td>\n",
       "      <td>203.195044</td>\n",
       "      <td>202.258742</td>\n",
       "      <td>201.190437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-05-03</th>\n",
       "      <td>199.800003</td>\n",
       "      <td>200.289406</td>\n",
       "      <td>198.502655</td>\n",
       "      <td>200.513331</td>\n",
       "      <td>202.551651</td>\n",
       "      <td>200.062714</td>\n",
       "      <td>201.090623</td>\n",
       "      <td>201.154306</td>\n",
       "      <td>200.887828</td>\n",
       "      <td>200.225112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-05-04</th>\n",
       "      <td>196.500000</td>\n",
       "      <td>199.756678</td>\n",
       "      <td>198.502655</td>\n",
       "      <td>200.534391</td>\n",
       "      <td>201.964355</td>\n",
       "      <td>199.107666</td>\n",
       "      <td>201.090623</td>\n",
       "      <td>201.106923</td>\n",
       "      <td>200.710956</td>\n",
       "      <td>199.724090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-05-05</th>\n",
       "      <td>191.350006</td>\n",
       "      <td>197.013639</td>\n",
       "      <td>197.834320</td>\n",
       "      <td>198.453676</td>\n",
       "      <td>195.933411</td>\n",
       "      <td>196.240143</td>\n",
       "      <td>195.172344</td>\n",
       "      <td>197.284154</td>\n",
       "      <td>197.477560</td>\n",
       "      <td>197.096290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-05-08</th>\n",
       "      <td>193.500000</td>\n",
       "      <td>193.894887</td>\n",
       "      <td>200.221313</td>\n",
       "      <td>195.503333</td>\n",
       "      <td>195.496124</td>\n",
       "      <td>193.763168</td>\n",
       "      <td>195.172344</td>\n",
       "      <td>196.799901</td>\n",
       "      <td>196.926282</td>\n",
       "      <td>193.951872</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>441 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Adj Close  LR Prediction  DTR Prediction  MLP Prediction   \n",
       "Date                                                                    \n",
       "2021-08-11  215.904449     219.277143      216.575272      217.405019  \\\n",
       "2021-08-12  216.287766     217.267966      214.121323      215.149052   \n",
       "2021-08-13  217.054398     217.417704      217.246063      215.884530   \n",
       "2021-08-16  216.958542     217.590599      217.246063      216.133840   \n",
       "2021-08-17  216.096130     218.028584      217.246063      215.662954   \n",
       "...                ...            ...             ...             ...   \n",
       "2023-05-02  201.600006     201.056443      201.276337      202.359313   \n",
       "2023-05-03  199.800003     200.289406      198.502655      200.513331   \n",
       "2023-05-04  196.500000     199.756678      198.502655      200.534391   \n",
       "2023-05-05  191.350006     197.013639      197.834320      198.453676   \n",
       "2023-05-08  193.500000     193.894887      200.221313      195.503333   \n",
       "\n",
       "            XGBoost Prediction  XGBoost_LR Prediction  ADA Prediction   \n",
       "Date                                                                    \n",
       "2021-08-11          217.550354             218.676453      214.635613  \\\n",
       "2021-08-12          218.125473             217.685043      214.635613   \n",
       "2021-08-13          216.535248             217.933319      214.635613   \n",
       "2021-08-16          216.325745             218.288147      214.635613   \n",
       "2021-08-17          215.928650             218.767090      214.635613   \n",
       "...                        ...                    ...             ...   \n",
       "2023-05-02          200.872910             201.411545      197.779186   \n",
       "2023-05-03          202.551651             200.062714      201.090623   \n",
       "2023-05-04          201.964355             199.107666      201.090623   \n",
       "2023-05-05          195.933411             196.240143      195.172344   \n",
       "2023-05-08          195.496124             193.763168      195.172344   \n",
       "\n",
       "            GBR Prediction  Bagging Prediction  StackedRegressor Prediction  \n",
       "Date                                                                         \n",
       "2021-08-11      218.417178          217.868967                   219.263354  \n",
       "2021-08-12      217.241738          217.916881                   217.168788  \n",
       "2021-08-13      216.451197          216.517520                   217.367880  \n",
       "2021-08-16      216.690617          216.564281                   217.537270  \n",
       "2021-08-17      216.505656          216.790698                   217.997600  \n",
       "...                    ...                 ...                          ...  \n",
       "2023-05-02      203.195044          202.258742                   201.190437  \n",
       "2023-05-03      201.154306          200.887828                   200.225112  \n",
       "2023-05-04      201.106923          200.710956                   199.724090  \n",
       "2023-05-05      197.284154          197.477560                   197.096290  \n",
       "2023-05-08      196.799901          196.926282                   193.951872  \n",
       "\n",
       "[441 rows x 10 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CL=F\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>LR Prediction</th>\n",
       "      <th>DTR Prediction</th>\n",
       "      <th>MLP Prediction</th>\n",
       "      <th>XGBoost Prediction</th>\n",
       "      <th>XGBoost_LR Prediction</th>\n",
       "      <th>ADA Prediction</th>\n",
       "      <th>GBR Prediction</th>\n",
       "      <th>Bagging Prediction</th>\n",
       "      <th>StackedRegressor Prediction</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2021-08-13</th>\n",
       "      <td>68.440002</td>\n",
       "      <td>68.165812</td>\n",
       "      <td>66.820000</td>\n",
       "      <td>67.996134</td>\n",
       "      <td>68.740768</td>\n",
       "      <td>69.134277</td>\n",
       "      <td>69.023731</td>\n",
       "      <td>68.495539</td>\n",
       "      <td>67.295000</td>\n",
       "      <td>68.145306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-08-16</th>\n",
       "      <td>67.290001</td>\n",
       "      <td>67.899155</td>\n",
       "      <td>66.480003</td>\n",
       "      <td>67.649485</td>\n",
       "      <td>68.562996</td>\n",
       "      <td>68.643890</td>\n",
       "      <td>69.023731</td>\n",
       "      <td>67.955054</td>\n",
       "      <td>67.410001</td>\n",
       "      <td>67.893440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-08-17</th>\n",
       "      <td>66.589996</td>\n",
       "      <td>67.886667</td>\n",
       "      <td>66.430000</td>\n",
       "      <td>67.473132</td>\n",
       "      <td>67.772232</td>\n",
       "      <td>69.689308</td>\n",
       "      <td>69.023731</td>\n",
       "      <td>67.325084</td>\n",
       "      <td>67.495000</td>\n",
       "      <td>67.806822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-08-18</th>\n",
       "      <td>65.459999</td>\n",
       "      <td>67.789805</td>\n",
       "      <td>66.430000</td>\n",
       "      <td>67.460303</td>\n",
       "      <td>68.158363</td>\n",
       "      <td>69.411011</td>\n",
       "      <td>67.947079</td>\n",
       "      <td>67.857614</td>\n",
       "      <td>67.639999</td>\n",
       "      <td>67.733627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-08-19</th>\n",
       "      <td>63.689999</td>\n",
       "      <td>66.443057</td>\n",
       "      <td>66.809998</td>\n",
       "      <td>66.365724</td>\n",
       "      <td>66.044060</td>\n",
       "      <td>67.855118</td>\n",
       "      <td>67.138213</td>\n",
       "      <td>66.453508</td>\n",
       "      <td>66.535000</td>\n",
       "      <td>66.371286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-05-02</th>\n",
       "      <td>71.660004</td>\n",
       "      <td>74.620481</td>\n",
       "      <td>74.209999</td>\n",
       "      <td>75.374098</td>\n",
       "      <td>75.419594</td>\n",
       "      <td>75.149574</td>\n",
       "      <td>73.729856</td>\n",
       "      <td>74.381626</td>\n",
       "      <td>74.882999</td>\n",
       "      <td>74.830649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-05-03</th>\n",
       "      <td>68.599998</td>\n",
       "      <td>70.845895</td>\n",
       "      <td>74.580002</td>\n",
       "      <td>71.989872</td>\n",
       "      <td>74.956955</td>\n",
       "      <td>70.775650</td>\n",
       "      <td>73.426117</td>\n",
       "      <td>72.282750</td>\n",
       "      <td>73.865998</td>\n",
       "      <td>71.286449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-05-04</th>\n",
       "      <td>68.559998</td>\n",
       "      <td>69.850691</td>\n",
       "      <td>71.650002</td>\n",
       "      <td>71.508773</td>\n",
       "      <td>70.132805</td>\n",
       "      <td>69.676292</td>\n",
       "      <td>72.277657</td>\n",
       "      <td>70.915482</td>\n",
       "      <td>69.914999</td>\n",
       "      <td>69.955306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-05-05</th>\n",
       "      <td>71.339996</td>\n",
       "      <td>70.923995</td>\n",
       "      <td>71.650002</td>\n",
       "      <td>72.545273</td>\n",
       "      <td>71.154556</td>\n",
       "      <td>71.036789</td>\n",
       "      <td>70.900383</td>\n",
       "      <td>71.421057</td>\n",
       "      <td>70.345000</td>\n",
       "      <td>71.099960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-05-08</th>\n",
       "      <td>73.160004</td>\n",
       "      <td>72.083640</td>\n",
       "      <td>69.000000</td>\n",
       "      <td>73.581711</td>\n",
       "      <td>70.645622</td>\n",
       "      <td>72.821587</td>\n",
       "      <td>70.704519</td>\n",
       "      <td>71.541450</td>\n",
       "      <td>69.267000</td>\n",
       "      <td>72.212705</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>439 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Adj Close  LR Prediction  DTR Prediction  MLP Prediction   \n",
       "Date                                                                   \n",
       "2021-08-13  68.440002      68.165812       66.820000       67.996134  \\\n",
       "2021-08-16  67.290001      67.899155       66.480003       67.649485   \n",
       "2021-08-17  66.589996      67.886667       66.430000       67.473132   \n",
       "2021-08-18  65.459999      67.789805       66.430000       67.460303   \n",
       "2021-08-19  63.689999      66.443057       66.809998       66.365724   \n",
       "...               ...            ...             ...             ...   \n",
       "2023-05-02  71.660004      74.620481       74.209999       75.374098   \n",
       "2023-05-03  68.599998      70.845895       74.580002       71.989872   \n",
       "2023-05-04  68.559998      69.850691       71.650002       71.508773   \n",
       "2023-05-05  71.339996      70.923995       71.650002       72.545273   \n",
       "2023-05-08  73.160004      72.083640       69.000000       73.581711   \n",
       "\n",
       "            XGBoost Prediction  XGBoost_LR Prediction  ADA Prediction   \n",
       "Date                                                                    \n",
       "2021-08-13           68.740768              69.134277       69.023731  \\\n",
       "2021-08-16           68.562996              68.643890       69.023731   \n",
       "2021-08-17           67.772232              69.689308       69.023731   \n",
       "2021-08-18           68.158363              69.411011       67.947079   \n",
       "2021-08-19           66.044060              67.855118       67.138213   \n",
       "...                        ...                    ...             ...   \n",
       "2023-05-02           75.419594              75.149574       73.729856   \n",
       "2023-05-03           74.956955              70.775650       73.426117   \n",
       "2023-05-04           70.132805              69.676292       72.277657   \n",
       "2023-05-05           71.154556              71.036789       70.900383   \n",
       "2023-05-08           70.645622              72.821587       70.704519   \n",
       "\n",
       "            GBR Prediction  Bagging Prediction  StackedRegressor Prediction  \n",
       "Date                                                                         \n",
       "2021-08-13       68.495539           67.295000                    68.145306  \n",
       "2021-08-16       67.955054           67.410001                    67.893440  \n",
       "2021-08-17       67.325084           67.495000                    67.806822  \n",
       "2021-08-18       67.857614           67.639999                    67.733627  \n",
       "2021-08-19       66.453508           66.535000                    66.371286  \n",
       "...                    ...                 ...                          ...  \n",
       "2023-05-02       74.381626           74.882999                    74.830649  \n",
       "2023-05-03       72.282750           73.865998                    71.286449  \n",
       "2023-05-04       70.915482           69.914999                    69.955306  \n",
       "2023-05-05       71.421057           70.345000                    71.099960  \n",
       "2023-05-08       71.541450           69.267000                    72.212705  \n",
       "\n",
       "[439 rows x 10 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OSEBX.OL\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>LR Prediction</th>\n",
       "      <th>DTR Prediction</th>\n",
       "      <th>MLP Prediction</th>\n",
       "      <th>XGBoost Prediction</th>\n",
       "      <th>XGBoost_LR Prediction</th>\n",
       "      <th>ADA Prediction</th>\n",
       "      <th>GBR Prediction</th>\n",
       "      <th>Bagging Prediction</th>\n",
       "      <th>StackedRegressor Prediction</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2021-10-22</th>\n",
       "      <td>1217.709961</td>\n",
       "      <td>1211.440835</td>\n",
       "      <td>1217.469971</td>\n",
       "      <td>1198.608059</td>\n",
       "      <td>1207.861328</td>\n",
       "      <td>1186.326538</td>\n",
       "      <td>1189.720101</td>\n",
       "      <td>1202.033309</td>\n",
       "      <td>1206.851978</td>\n",
       "      <td>1211.937267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-10-25</th>\n",
       "      <td>1215.099976</td>\n",
       "      <td>1219.210989</td>\n",
       "      <td>1217.469971</td>\n",
       "      <td>1206.956815</td>\n",
       "      <td>1209.122437</td>\n",
       "      <td>1194.847900</td>\n",
       "      <td>1189.720101</td>\n",
       "      <td>1203.789945</td>\n",
       "      <td>1207.803979</td>\n",
       "      <td>1219.897165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-10-26</th>\n",
       "      <td>1215.739990</td>\n",
       "      <td>1215.234722</td>\n",
       "      <td>1217.469971</td>\n",
       "      <td>1203.440291</td>\n",
       "      <td>1207.066284</td>\n",
       "      <td>1190.081909</td>\n",
       "      <td>1189.720101</td>\n",
       "      <td>1203.063291</td>\n",
       "      <td>1206.851978</td>\n",
       "      <td>1215.823763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-10-27</th>\n",
       "      <td>1211.869995</td>\n",
       "      <td>1218.774696</td>\n",
       "      <td>1217.469971</td>\n",
       "      <td>1208.287866</td>\n",
       "      <td>1207.745117</td>\n",
       "      <td>1195.960449</td>\n",
       "      <td>1189.720101</td>\n",
       "      <td>1203.063291</td>\n",
       "      <td>1207.803979</td>\n",
       "      <td>1219.428946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-10-28</th>\n",
       "      <td>1202.089966</td>\n",
       "      <td>1213.151088</td>\n",
       "      <td>1217.469971</td>\n",
       "      <td>1205.008373</td>\n",
       "      <td>1208.679077</td>\n",
       "      <td>1191.535522</td>\n",
       "      <td>1189.720101</td>\n",
       "      <td>1202.033309</td>\n",
       "      <td>1206.851978</td>\n",
       "      <td>1213.767367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-05-02</th>\n",
       "      <td>1208.410034</td>\n",
       "      <td>1221.809359</td>\n",
       "      <td>1217.469971</td>\n",
       "      <td>1221.840198</td>\n",
       "      <td>1211.428711</td>\n",
       "      <td>1212.672485</td>\n",
       "      <td>1189.720101</td>\n",
       "      <td>1208.909152</td>\n",
       "      <td>1207.803979</td>\n",
       "      <td>1222.779471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-05-03</th>\n",
       "      <td>1203.479980</td>\n",
       "      <td>1199.928514</td>\n",
       "      <td>1217.469971</td>\n",
       "      <td>1200.306298</td>\n",
       "      <td>1199.211182</td>\n",
       "      <td>1187.240234</td>\n",
       "      <td>1189.720101</td>\n",
       "      <td>1193.040876</td>\n",
       "      <td>1207.096985</td>\n",
       "      <td>1200.858668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-05-04</th>\n",
       "      <td>1189.719971</td>\n",
       "      <td>1209.028723</td>\n",
       "      <td>1217.469971</td>\n",
       "      <td>1213.750717</td>\n",
       "      <td>1204.815674</td>\n",
       "      <td>1195.505249</td>\n",
       "      <td>1189.720101</td>\n",
       "      <td>1198.345987</td>\n",
       "      <td>1205.402979</td>\n",
       "      <td>1210.470494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-05-05</th>\n",
       "      <td>1204.540039</td>\n",
       "      <td>1197.968307</td>\n",
       "      <td>1217.469971</td>\n",
       "      <td>1204.103023</td>\n",
       "      <td>1195.100830</td>\n",
       "      <td>1182.949463</td>\n",
       "      <td>1189.720101</td>\n",
       "      <td>1185.367440</td>\n",
       "      <td>1203.974976</td>\n",
       "      <td>1198.773298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-05-08</th>\n",
       "      <td>1213.089966</td>\n",
       "      <td>1215.845533</td>\n",
       "      <td>1217.469971</td>\n",
       "      <td>1226.181441</td>\n",
       "      <td>1206.488159</td>\n",
       "      <td>1203.194946</td>\n",
       "      <td>1189.720101</td>\n",
       "      <td>1200.661734</td>\n",
       "      <td>1205.951978</td>\n",
       "      <td>1217.474559</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>389 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              Adj Close  LR Prediction  DTR Prediction  MLP Prediction   \n",
       "Date                                                                     \n",
       "2021-10-22  1217.709961    1211.440835     1217.469971     1198.608059  \\\n",
       "2021-10-25  1215.099976    1219.210989     1217.469971     1206.956815   \n",
       "2021-10-26  1215.739990    1215.234722     1217.469971     1203.440291   \n",
       "2021-10-27  1211.869995    1218.774696     1217.469971     1208.287866   \n",
       "2021-10-28  1202.089966    1213.151088     1217.469971     1205.008373   \n",
       "...                 ...            ...             ...             ...   \n",
       "2023-05-02  1208.410034    1221.809359     1217.469971     1221.840198   \n",
       "2023-05-03  1203.479980    1199.928514     1217.469971     1200.306298   \n",
       "2023-05-04  1189.719971    1209.028723     1217.469971     1213.750717   \n",
       "2023-05-05  1204.540039    1197.968307     1217.469971     1204.103023   \n",
       "2023-05-08  1213.089966    1215.845533     1217.469971     1226.181441   \n",
       "\n",
       "            XGBoost Prediction  XGBoost_LR Prediction  ADA Prediction   \n",
       "Date                                                                    \n",
       "2021-10-22         1207.861328            1186.326538     1189.720101  \\\n",
       "2021-10-25         1209.122437            1194.847900     1189.720101   \n",
       "2021-10-26         1207.066284            1190.081909     1189.720101   \n",
       "2021-10-27         1207.745117            1195.960449     1189.720101   \n",
       "2021-10-28         1208.679077            1191.535522     1189.720101   \n",
       "...                        ...                    ...             ...   \n",
       "2023-05-02         1211.428711            1212.672485     1189.720101   \n",
       "2023-05-03         1199.211182            1187.240234     1189.720101   \n",
       "2023-05-04         1204.815674            1195.505249     1189.720101   \n",
       "2023-05-05         1195.100830            1182.949463     1189.720101   \n",
       "2023-05-08         1206.488159            1203.194946     1189.720101   \n",
       "\n",
       "            GBR Prediction  Bagging Prediction  StackedRegressor Prediction  \n",
       "Date                                                                         \n",
       "2021-10-22     1202.033309         1206.851978                  1211.937267  \n",
       "2021-10-25     1203.789945         1207.803979                  1219.897165  \n",
       "2021-10-26     1203.063291         1206.851978                  1215.823763  \n",
       "2021-10-27     1203.063291         1207.803979                  1219.428946  \n",
       "2021-10-28     1202.033309         1206.851978                  1213.767367  \n",
       "...                    ...                 ...                          ...  \n",
       "2023-05-02     1208.909152         1207.803979                  1222.779471  \n",
       "2023-05-03     1193.040876         1207.096985                  1200.858668  \n",
       "2023-05-04     1198.345987         1205.402979                  1210.470494  \n",
       "2023-05-05     1185.367440         1203.974976                  1198.773298  \n",
       "2023-05-08     1200.661734         1205.951978                  1217.474559  \n",
       "\n",
       "[389 rows x 10 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for ticker in stocks_list:\n",
    "    print(ticker)\n",
    "    display(predicted_stock_data[ticker])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_df_output = {}\n",
    "def print_metrics(save_data_to_df=True):\n",
    "    for ticker, data in stock_data.items():\n",
    "        print(\"\\n--------\", ticker, \"--------\")\n",
    "\n",
    "        # prepare dataframe if requested\n",
    "        if save_data_to_df:\n",
    "            metrics_df = pd.DataFrame(index=list(pretty_metric_names.values()))\n",
    "            metrics_df_output[ticker] = metrics_df\n",
    "            current_metrics_df = metrics_df\n",
    "\n",
    "        for model_name in models:        \n",
    "            cv = cv_results[ticker+\"_model_\"+model_name]\n",
    "\n",
    "            print(\"-\", model_name, \"-\")\n",
    "            print(\"-\", \"Training Scores:\", \"-\")\n",
    "            split1_errors_string = f\"Score for first data split \\n\"\n",
    "            split3_errors_string = f\"Score for third data split \\n\"\n",
    "            split5_errors_string = f\"Score for last data split \\n\"\n",
    "\n",
    "            for error_metric_name in metric_names:\n",
    "                # some metrics are saved as negative, so change sign\n",
    "                if error_metric_name.startswith(\"neg\"):\n",
    "                    try:\n",
    "                        error_metric_value = -cv[\"train\"+\"_\"+error_metric_name]\n",
    "                    # string being passed that can't be negative\n",
    "                    except:\n",
    "                        error_metric_value = cv[\"train\"+\"_\"+error_metric_name]\n",
    "                else:\n",
    "                    error_metric_value = cv[\"train\"+\"_\"+error_metric_name]\n",
    "\n",
    "                if save_data_to_df:\n",
    "                    # pass string, used to indicate missing metrics\n",
    "                    if isinstance(error_metric_value, str):\n",
    "                        current_metrics_df.loc[pretty_metric_names[error_metric_name], model_name+\" Model \"+\"Train\"] = error_metric_value\n",
    "                    # otherwise mean of all splits\n",
    "                    else:\n",
    "                        current_metrics_df.loc[pretty_metric_names[error_metric_name], model_name+\" Model \"+\"Train\"] = np.mean(error_metric_value)\n",
    "        \n",
    "                if isinstance(error_metric_value, str):\n",
    "                    split1_errors_string += f\"{pretty_metric_names[error_metric_name]} {error_metric_value}\\n\"\n",
    "                else:\n",
    "                    split1_errors_string += f\"{pretty_metric_names[error_metric_name]} {error_metric_value[0]:.3f}\\n\"\n",
    "\n",
    "                if isinstance(error_metric_value, str):\n",
    "                    split3_errors_string += f\"{pretty_metric_names[error_metric_name]} {error_metric_value}\\n\"\n",
    "                else:\n",
    "                    split3_errors_string += f\"{pretty_metric_names[error_metric_name]} {error_metric_value[2]:.3f}\\n\"\n",
    "    \n",
    "                if isinstance(error_metric_value, str):\n",
    "                    split5_errors_string += f\"{pretty_metric_names[error_metric_name]} {error_metric_value}\\n\"\n",
    "                else:\n",
    "                    split5_errors_string += f\"{pretty_metric_names[error_metric_name]} {error_metric_value[-1]:.3f}\\n\"\n",
    "\n",
    "            # print the two strings\n",
    "            print(split1_errors_string+\"\\n\"+split3_errors_string+\"\\n\"+split5_errors_string+\"\\n\")\n",
    "            \n",
    "            print(\"-\", \"Testing Scores:\", \"-\")\n",
    "            split1_errors_string = f\"Score for first data split \\n\"\n",
    "            split3_errors_string = f\"Score for third data split \\n\"\n",
    "            split5_errors_string = f\"Score for last data split \\n\"\n",
    "\n",
    "            for error_metric_name in metric_names:\n",
    "                # some metrics are saved as negative, so change sign\n",
    "                if error_metric_name.startswith(\"neg\"):\n",
    "                    try:\n",
    "                        error_metric_value = -cv[\"test\"+\"_\"+error_metric_name]\n",
    "                    # string being passed that can't be negative\n",
    "                    except:\n",
    "                        error_metric_value = cv[\"test\"+\"_\"+error_metric_name]\n",
    "                else:\n",
    "                    error_metric_value = cv[\"test\"+\"_\"+error_metric_name]\n",
    "\n",
    "                if save_data_to_df:\n",
    "                    # pass string, used to indicate missing metrics\n",
    "                    if isinstance(error_metric_value, str):\n",
    "                        current_metrics_df.loc[pretty_metric_names[error_metric_name], model_name+\" Model \"+\"Test\"] = error_metric_value\n",
    "                    # otherwise mean of all splits\n",
    "                    else:\n",
    "                        current_metrics_df.loc[pretty_metric_names[error_metric_name], model_name+\" Model \"+\"Test\"] = np.mean(error_metric_value)\n",
    "        \n",
    "                if isinstance(error_metric_value, str):\n",
    "                    split1_errors_string += f\"{pretty_metric_names[error_metric_name]} {error_metric_value}\\n\"\n",
    "                else:\n",
    "                    split1_errors_string += f\"{pretty_metric_names[error_metric_name]} {error_metric_value[0]:.3f}\\n\"\n",
    "\n",
    "                if isinstance(error_metric_value, str):\n",
    "                    split3_errors_string += f\"{pretty_metric_names[error_metric_name]} {error_metric_value}\\n\"\n",
    "                else:\n",
    "                    split3_errors_string += f\"{pretty_metric_names[error_metric_name]} {error_metric_value[2]:.3f}\\n\"\n",
    "\n",
    "                if isinstance(error_metric_value, str):\n",
    "                    split5_errors_string += f\"{pretty_metric_names[error_metric_name]} {error_metric_value}\\n\"\n",
    "                else:\n",
    "                    split5_errors_string += f\"{pretty_metric_names[error_metric_name]} {error_metric_value[-1]:.3f}\\n\"\n",
    "\n",
    "            # print the two strings\n",
    "            print(split1_errors_string+\"\\n\"+split3_errors_string+\"\\n\"+split5_errors_string+\"\\n\")\n",
    "\n",
    "    if save_data_to_df:\n",
    "        return metrics_df_output\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_output = print_metrics(save_data_to_df=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plots for insights about the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PLOT FOR SHOWING DIFFERENT DATA SPLITS FOR THE DIFFERENT STOCKS\n",
    "for ticker in stocks_list:\n",
    "    fig, sub_plots = plt.subplots(n_splits, figsize=(16,20))\n",
    "    fig.set_tight_layout(True)\n",
    "\n",
    "    data = stock_data[ticker]\n",
    "    idx = data.index\n",
    "\n",
    "    tscv = TimeSeriesSplit(n_splits=n_splits)\n",
    "\n",
    "    splits = list(tscv.split(data))\n",
    "        \n",
    "    current_split = 1\n",
    "    for i in range(len(sub_plots)):\n",
    "        train_index, test_index = splits[i]\n",
    "\n",
    "        sub_plots[i].plot(idx[train_index], data.loc[idx[train_index], main_col], label=f\"Training data {current_split}\", color=\"blue\")\n",
    "        sub_plots[i].plot(idx[test_index], data.loc[idx[test_index], main_col], label=f\"Test data {current_split}\", color=\"red\")\n",
    "        sub_plots[i].set_xlim(idx[0], idx[-1])\n",
    "        sub_plots[i].set_title(f\"Train / test split {current_split} for {ticker}\")\n",
    "        sub_plots[i].set_xlabel(\"Date\")\n",
    "        sub_plots[i].set_ylabel(f\"{main_col}\")\n",
    "        sub_plots[i].legend()\n",
    "\n",
    "        current_split = current_split + 1\n",
    "    \n",
    "    #fig.savefig(\"data_splits_plots/\"+ticker+\".png\")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PLOT FOR COMPARING ACTUAL TO THE DIFFERENT MODELS PREDICTED VALUES\n",
    "for ticker, data in stock_data.items():\n",
    "    figure, axs = plt.subplots(figsize=(32,16))\n",
    "    \n",
    "    X, y = create_X_y_arrays(data=data, label_name=\"Label\")\n",
    "    X_train, X_test, y_train, y_test = create_X_y_train_test_split(X=X, y=y, current_stock=ticker)\n",
    "\n",
    "    X_test_index = np.arange(X_train.shape[0], X_train.shape[0]+X_test.shape[0])\n",
    "\n",
    "    print(X_test_index)\n",
    "\n",
    "    plt.plot(data.index[X_test_index], y_test, color='purple', label='Actual', linewidth=\"4.0\")\n",
    "    for model in models:\n",
    "        plt.plot(data.index[X_test_index], stock_predictions[ticker][model+\" Prediction\"], label=model)\n",
    "    plt.title(f'Actual vs Predicted, {ticker}')\n",
    "    plt.xlabel('Date')\n",
    "    plt.ylabel('Price')\n",
    "    plt.legend()\n",
    "\n",
    "    #plt.savefig(\"actual_predicted_plots/\"+ticker+\".png\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CORRELATION PLOT BETWEEN THE DIFFERENT STOCKS\n",
    "adj_close_prices = pd.DataFrame({i: j[main_col] for i, j in stock_data.items()})\n",
    "\n",
    "corr = adj_close_prices.corr()\n",
    "\n",
    "sns.heatmap(corr, cmap=\"coolwarm\", annot=True)\n",
    "\n",
    "plt.title(\"Correlation between stocks\")\n",
    "\n",
    "#plt.savefig(\"correlation_plots/correlation_stocks.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EQNR.OL\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LR Model Train</th>\n",
       "      <th>LR Model Test</th>\n",
       "      <th>DTR Model Train</th>\n",
       "      <th>DTR Model Test</th>\n",
       "      <th>MLP Model Train</th>\n",
       "      <th>MLP Model Test</th>\n",
       "      <th>XGBoost Model Train</th>\n",
       "      <th>XGBoost Model Test</th>\n",
       "      <th>XGBoost_LR Model Train</th>\n",
       "      <th>XGBoost_LR Model Test</th>\n",
       "      <th>ADA Model Train</th>\n",
       "      <th>ADA Model Test</th>\n",
       "      <th>GBR Model Train</th>\n",
       "      <th>GBR Model Test</th>\n",
       "      <th>Bagging Model Train</th>\n",
       "      <th>Bagging Model Test</th>\n",
       "      <th>StackedRegressor Model Train</th>\n",
       "      <th>StackedRegressor Model Test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>R^2:</th>\n",
       "      <td>0.996985</td>\n",
       "      <td>0.990769</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.214380</td>\n",
       "      <td>0.991094</td>\n",
       "      <td>0.964790</td>\n",
       "      <td>0.999925</td>\n",
       "      <td>-0.266899</td>\n",
       "      <td>0.967126</td>\n",
       "      <td>0.734653</td>\n",
       "      <td>0.990928</td>\n",
       "      <td>-0.270874</td>\n",
       "      <td>0.998195</td>\n",
       "      <td>-0.232131</td>\n",
       "      <td>0.999012</td>\n",
       "      <td>-0.268687</td>\n",
       "      <td>0.996932</td>\n",
       "      <td>0.987479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MAE:</th>\n",
       "      <td>0.743181</td>\n",
       "      <td>1.633022</td>\n",
       "      <td>0.0</td>\n",
       "      <td>26.163471</td>\n",
       "      <td>1.231936</td>\n",
       "      <td>2.508528</td>\n",
       "      <td>0.127656</td>\n",
       "      <td>26.172964</td>\n",
       "      <td>2.322553</td>\n",
       "      <td>7.160678</td>\n",
       "      <td>1.446361</td>\n",
       "      <td>26.416699</td>\n",
       "      <td>0.615402</td>\n",
       "      <td>25.669145</td>\n",
       "      <td>0.376656</td>\n",
       "      <td>26.417137</td>\n",
       "      <td>0.744425</td>\n",
       "      <td>2.332848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE:</th>\n",
       "      <td>1.062961</td>\n",
       "      <td>5.990698</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2973.662219</td>\n",
       "      <td>2.620583</td>\n",
       "      <td>12.762969</td>\n",
       "      <td>0.046184</td>\n",
       "      <td>3030.749249</td>\n",
       "      <td>8.299787</td>\n",
       "      <td>81.274224</td>\n",
       "      <td>3.599389</td>\n",
       "      <td>3000.766230</td>\n",
       "      <td>0.724019</td>\n",
       "      <td>2921.262496</td>\n",
       "      <td>0.333223</td>\n",
       "      <td>3002.072999</td>\n",
       "      <td>1.053638</td>\n",
       "      <td>16.429672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RMSE:</th>\n",
       "      <td>1.001151</td>\n",
       "      <td>2.077144</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30.677009</td>\n",
       "      <td>1.609779</td>\n",
       "      <td>3.207665</td>\n",
       "      <td>0.177935</td>\n",
       "      <td>30.737324</td>\n",
       "      <td>2.845208</td>\n",
       "      <td>8.198133</td>\n",
       "      <td>1.813293</td>\n",
       "      <td>31.063832</td>\n",
       "      <td>0.797773</td>\n",
       "      <td>30.337502</td>\n",
       "      <td>0.561429</td>\n",
       "      <td>31.055130</td>\n",
       "      <td>1.000669</td>\n",
       "      <td>2.880701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MAPE:</th>\n",
       "      <td>0.006715</td>\n",
       "      <td>0.009519</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.099931</td>\n",
       "      <td>0.011304</td>\n",
       "      <td>0.016034</td>\n",
       "      <td>0.001123</td>\n",
       "      <td>0.097844</td>\n",
       "      <td>0.021952</td>\n",
       "      <td>0.044400</td>\n",
       "      <td>0.013135</td>\n",
       "      <td>0.100877</td>\n",
       "      <td>0.005528</td>\n",
       "      <td>0.096896</td>\n",
       "      <td>0.003430</td>\n",
       "      <td>0.102535</td>\n",
       "      <td>0.006736</td>\n",
       "      <td>0.011704</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        LR Model Train  LR Model Test  DTR Model Train  DTR Model Test   \n",
       "R^2:          0.996985       0.990769              1.0       -0.214380  \\\n",
       "MAE:          0.743181       1.633022              0.0       26.163471   \n",
       "MSE:          1.062961       5.990698              0.0     2973.662219   \n",
       "RMSE:         1.001151       2.077144              0.0       30.677009   \n",
       "MAPE:         0.006715       0.009519              0.0        0.099931   \n",
       "\n",
       "        MLP Model Train  MLP Model Test  XGBoost Model Train   \n",
       "R^2:           0.991094        0.964790             0.999925  \\\n",
       "MAE:           1.231936        2.508528             0.127656   \n",
       "MSE:           2.620583       12.762969             0.046184   \n",
       "RMSE:          1.609779        3.207665             0.177935   \n",
       "MAPE:          0.011304        0.016034             0.001123   \n",
       "\n",
       "        XGBoost Model Test  XGBoost_LR Model Train  XGBoost_LR Model Test   \n",
       "R^2:             -0.266899                0.967126               0.734653  \\\n",
       "MAE:             26.172964                2.322553               7.160678   \n",
       "MSE:           3030.749249                8.299787              81.274224   \n",
       "RMSE:            30.737324                2.845208               8.198133   \n",
       "MAPE:             0.097844                0.021952               0.044400   \n",
       "\n",
       "        ADA Model Train  ADA Model Test  GBR Model Train  GBR Model Test   \n",
       "R^2:           0.990928       -0.270874         0.998195       -0.232131  \\\n",
       "MAE:           1.446361       26.416699         0.615402       25.669145   \n",
       "MSE:           3.599389     3000.766230         0.724019     2921.262496   \n",
       "RMSE:          1.813293       31.063832         0.797773       30.337502   \n",
       "MAPE:          0.013135        0.100877         0.005528        0.096896   \n",
       "\n",
       "        Bagging Model Train  Bagging Model Test  StackedRegressor Model Train   \n",
       "R^2:               0.999012           -0.268687                      0.996932  \\\n",
       "MAE:               0.376656           26.417137                      0.744425   \n",
       "MSE:               0.333223         3002.072999                      1.053638   \n",
       "RMSE:              0.561429           31.055130                      1.000669   \n",
       "MAPE:              0.003430            0.102535                      0.006736   \n",
       "\n",
       "        StackedRegressor Model Test  \n",
       "R^2:                       0.987479  \n",
       "MAE:                       2.332848  \n",
       "MSE:                      16.429672  \n",
       "RMSE:                      2.880701  \n",
       "MAPE:                      0.011704  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DNB.OL\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LR Model Train</th>\n",
       "      <th>LR Model Test</th>\n",
       "      <th>DTR Model Train</th>\n",
       "      <th>DTR Model Test</th>\n",
       "      <th>MLP Model Train</th>\n",
       "      <th>MLP Model Test</th>\n",
       "      <th>XGBoost Model Train</th>\n",
       "      <th>XGBoost Model Test</th>\n",
       "      <th>XGBoost_LR Model Train</th>\n",
       "      <th>XGBoost_LR Model Test</th>\n",
       "      <th>ADA Model Train</th>\n",
       "      <th>ADA Model Test</th>\n",
       "      <th>GBR Model Train</th>\n",
       "      <th>GBR Model Test</th>\n",
       "      <th>Bagging Model Train</th>\n",
       "      <th>Bagging Model Test</th>\n",
       "      <th>StackedRegressor Model Train</th>\n",
       "      <th>StackedRegressor Model Test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>R^2:</th>\n",
       "      <td>0.998002</td>\n",
       "      <td>0.983546</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.856536</td>\n",
       "      <td>0.992907</td>\n",
       "      <td>0.945687</td>\n",
       "      <td>0.999953</td>\n",
       "      <td>-0.871664</td>\n",
       "      <td>0.980911</td>\n",
       "      <td>0.866086</td>\n",
       "      <td>0.993257</td>\n",
       "      <td>-1.434293</td>\n",
       "      <td>0.998953</td>\n",
       "      <td>-0.786255</td>\n",
       "      <td>0.999328</td>\n",
       "      <td>-0.802833</td>\n",
       "      <td>0.998035</td>\n",
       "      <td>0.983394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MAE:</th>\n",
       "      <td>0.509645</td>\n",
       "      <td>0.868352</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.359718</td>\n",
       "      <td>0.816137</td>\n",
       "      <td>1.508948</td>\n",
       "      <td>0.090386</td>\n",
       "      <td>9.347225</td>\n",
       "      <td>1.391779</td>\n",
       "      <td>3.066436</td>\n",
       "      <td>1.062995</td>\n",
       "      <td>10.489471</td>\n",
       "      <td>0.408647</td>\n",
       "      <td>9.017193</td>\n",
       "      <td>0.259506</td>\n",
       "      <td>9.089574</td>\n",
       "      <td>0.503361</td>\n",
       "      <td>0.864117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE:</th>\n",
       "      <td>0.493871</td>\n",
       "      <td>1.428907</td>\n",
       "      <td>0.0</td>\n",
       "      <td>174.136664</td>\n",
       "      <td>1.140976</td>\n",
       "      <td>5.585848</td>\n",
       "      <td>0.021377</td>\n",
       "      <td>176.014437</td>\n",
       "      <td>3.226879</td>\n",
       "      <td>15.043678</td>\n",
       "      <td>1.970143</td>\n",
       "      <td>219.629367</td>\n",
       "      <td>0.319329</td>\n",
       "      <td>167.390655</td>\n",
       "      <td>0.175546</td>\n",
       "      <td>168.103330</td>\n",
       "      <td>0.479535</td>\n",
       "      <td>1.435764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RMSE:</th>\n",
       "      <td>0.686201</td>\n",
       "      <td>1.133516</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.278676</td>\n",
       "      <td>1.065704</td>\n",
       "      <td>2.137921</td>\n",
       "      <td>0.124787</td>\n",
       "      <td>12.418069</td>\n",
       "      <td>1.791846</td>\n",
       "      <td>3.646611</td>\n",
       "      <td>1.334923</td>\n",
       "      <td>13.430718</td>\n",
       "      <td>0.535573</td>\n",
       "      <td>12.013536</td>\n",
       "      <td>0.403432</td>\n",
       "      <td>12.067085</td>\n",
       "      <td>0.677175</td>\n",
       "      <td>1.136575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MAPE:</th>\n",
       "      <td>0.007209</td>\n",
       "      <td>0.008043</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.073903</td>\n",
       "      <td>0.012102</td>\n",
       "      <td>0.016030</td>\n",
       "      <td>0.001229</td>\n",
       "      <td>0.073846</td>\n",
       "      <td>0.022169</td>\n",
       "      <td>0.030361</td>\n",
       "      <td>0.015285</td>\n",
       "      <td>0.080857</td>\n",
       "      <td>0.005683</td>\n",
       "      <td>0.070377</td>\n",
       "      <td>0.003664</td>\n",
       "      <td>0.071104</td>\n",
       "      <td>0.007145</td>\n",
       "      <td>0.008027</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        LR Model Train  LR Model Test  DTR Model Train  DTR Model Test   \n",
       "R^2:          0.998002       0.983546              1.0       -0.856536  \\\n",
       "MAE:          0.509645       0.868352              0.0        9.359718   \n",
       "MSE:          0.493871       1.428907              0.0      174.136664   \n",
       "RMSE:         0.686201       1.133516              0.0       12.278676   \n",
       "MAPE:         0.007209       0.008043              0.0        0.073903   \n",
       "\n",
       "        MLP Model Train  MLP Model Test  XGBoost Model Train   \n",
       "R^2:           0.992907        0.945687             0.999953  \\\n",
       "MAE:           0.816137        1.508948             0.090386   \n",
       "MSE:           1.140976        5.585848             0.021377   \n",
       "RMSE:          1.065704        2.137921             0.124787   \n",
       "MAPE:          0.012102        0.016030             0.001229   \n",
       "\n",
       "        XGBoost Model Test  XGBoost_LR Model Train  XGBoost_LR Model Test   \n",
       "R^2:             -0.871664                0.980911               0.866086  \\\n",
       "MAE:              9.347225                1.391779               3.066436   \n",
       "MSE:            176.014437                3.226879              15.043678   \n",
       "RMSE:            12.418069                1.791846               3.646611   \n",
       "MAPE:             0.073846                0.022169               0.030361   \n",
       "\n",
       "        ADA Model Train  ADA Model Test  GBR Model Train  GBR Model Test   \n",
       "R^2:           0.993257       -1.434293         0.998953       -0.786255  \\\n",
       "MAE:           1.062995       10.489471         0.408647        9.017193   \n",
       "MSE:           1.970143      219.629367         0.319329      167.390655   \n",
       "RMSE:          1.334923       13.430718         0.535573       12.013536   \n",
       "MAPE:          0.015285        0.080857         0.005683        0.070377   \n",
       "\n",
       "        Bagging Model Train  Bagging Model Test  StackedRegressor Model Train   \n",
       "R^2:               0.999328           -0.802833                      0.998035  \\\n",
       "MAE:               0.259506            9.089574                      0.503361   \n",
       "MSE:               0.175546          168.103330                      0.479535   \n",
       "RMSE:              0.403432           12.067085                      0.677175   \n",
       "MAPE:              0.003664            0.071104                      0.007145   \n",
       "\n",
       "        StackedRegressor Model Test  \n",
       "R^2:                       0.983394  \n",
       "MAE:                       0.864117  \n",
       "MSE:                       1.435764  \n",
       "RMSE:                      1.136575  \n",
       "MAPE:                      0.008027  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEL.OL\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LR Model Train</th>\n",
       "      <th>LR Model Test</th>\n",
       "      <th>DTR Model Train</th>\n",
       "      <th>DTR Model Test</th>\n",
       "      <th>MLP Model Train</th>\n",
       "      <th>MLP Model Test</th>\n",
       "      <th>XGBoost Model Train</th>\n",
       "      <th>XGBoost Model Test</th>\n",
       "      <th>XGBoost_LR Model Train</th>\n",
       "      <th>XGBoost_LR Model Test</th>\n",
       "      <th>ADA Model Train</th>\n",
       "      <th>ADA Model Test</th>\n",
       "      <th>GBR Model Train</th>\n",
       "      <th>GBR Model Test</th>\n",
       "      <th>Bagging Model Train</th>\n",
       "      <th>Bagging Model Test</th>\n",
       "      <th>StackedRegressor Model Train</th>\n",
       "      <th>StackedRegressor Model Test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>R^2:</th>\n",
       "      <td>0.997267</td>\n",
       "      <td>0.983683</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.472683</td>\n",
       "      <td>0.990040</td>\n",
       "      <td>0.965697</td>\n",
       "      <td>0.999944</td>\n",
       "      <td>0.512742</td>\n",
       "      <td>0.964627</td>\n",
       "      <td>0.766699</td>\n",
       "      <td>0.992190</td>\n",
       "      <td>0.469688</td>\n",
       "      <td>0.998584</td>\n",
       "      <td>0.557869</td>\n",
       "      <td>0.999168</td>\n",
       "      <td>0.530449</td>\n",
       "      <td>0.997098</td>\n",
       "      <td>0.983096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MAE:</th>\n",
       "      <td>0.566236</td>\n",
       "      <td>0.733967</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.106922</td>\n",
       "      <td>0.911540</td>\n",
       "      <td>1.190547</td>\n",
       "      <td>0.090641</td>\n",
       "      <td>3.757261</td>\n",
       "      <td>1.994093</td>\n",
       "      <td>3.218683</td>\n",
       "      <td>1.054456</td>\n",
       "      <td>4.186400</td>\n",
       "      <td>0.448504</td>\n",
       "      <td>3.595307</td>\n",
       "      <td>0.278473</td>\n",
       "      <td>3.760937</td>\n",
       "      <td>0.577446</td>\n",
       "      <td>0.754117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE:</th>\n",
       "      <td>0.580806</td>\n",
       "      <td>0.938487</td>\n",
       "      <td>0.0</td>\n",
       "      <td>43.533395</td>\n",
       "      <td>1.464095</td>\n",
       "      <td>2.442197</td>\n",
       "      <td>0.021967</td>\n",
       "      <td>43.290654</td>\n",
       "      <td>5.764096</td>\n",
       "      <td>17.742748</td>\n",
       "      <td>1.849286</td>\n",
       "      <td>47.275213</td>\n",
       "      <td>0.375936</td>\n",
       "      <td>40.035146</td>\n",
       "      <td>0.176833</td>\n",
       "      <td>41.980213</td>\n",
       "      <td>0.600166</td>\n",
       "      <td>0.982848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RMSE:</th>\n",
       "      <td>0.754305</td>\n",
       "      <td>0.959887</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.762163</td>\n",
       "      <td>1.201603</td>\n",
       "      <td>1.519934</td>\n",
       "      <td>0.125751</td>\n",
       "      <td>5.551631</td>\n",
       "      <td>2.398316</td>\n",
       "      <td>3.913891</td>\n",
       "      <td>1.330742</td>\n",
       "      <td>5.879049</td>\n",
       "      <td>0.590369</td>\n",
       "      <td>5.234063</td>\n",
       "      <td>0.416253</td>\n",
       "      <td>5.356821</td>\n",
       "      <td>0.768100</td>\n",
       "      <td>0.982606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MAPE:</th>\n",
       "      <td>0.006258</td>\n",
       "      <td>0.006577</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.036199</td>\n",
       "      <td>0.010326</td>\n",
       "      <td>0.010977</td>\n",
       "      <td>0.000974</td>\n",
       "      <td>0.032988</td>\n",
       "      <td>0.023752</td>\n",
       "      <td>0.028825</td>\n",
       "      <td>0.011745</td>\n",
       "      <td>0.036689</td>\n",
       "      <td>0.004880</td>\n",
       "      <td>0.031563</td>\n",
       "      <td>0.003075</td>\n",
       "      <td>0.033224</td>\n",
       "      <td>0.006391</td>\n",
       "      <td>0.006777</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        LR Model Train  LR Model Test  DTR Model Train  DTR Model Test   \n",
       "R^2:          0.997267       0.983683              1.0        0.472683  \\\n",
       "MAE:          0.566236       0.733967              0.0        4.106922   \n",
       "MSE:          0.580806       0.938487              0.0       43.533395   \n",
       "RMSE:         0.754305       0.959887              0.0        5.762163   \n",
       "MAPE:         0.006258       0.006577              0.0        0.036199   \n",
       "\n",
       "        MLP Model Train  MLP Model Test  XGBoost Model Train   \n",
       "R^2:           0.990040        0.965697             0.999944  \\\n",
       "MAE:           0.911540        1.190547             0.090641   \n",
       "MSE:           1.464095        2.442197             0.021967   \n",
       "RMSE:          1.201603        1.519934             0.125751   \n",
       "MAPE:          0.010326        0.010977             0.000974   \n",
       "\n",
       "        XGBoost Model Test  XGBoost_LR Model Train  XGBoost_LR Model Test   \n",
       "R^2:              0.512742                0.964627               0.766699  \\\n",
       "MAE:              3.757261                1.994093               3.218683   \n",
       "MSE:             43.290654                5.764096              17.742748   \n",
       "RMSE:             5.551631                2.398316               3.913891   \n",
       "MAPE:             0.032988                0.023752               0.028825   \n",
       "\n",
       "        ADA Model Train  ADA Model Test  GBR Model Train  GBR Model Test   \n",
       "R^2:           0.992190        0.469688         0.998584        0.557869  \\\n",
       "MAE:           1.054456        4.186400         0.448504        3.595307   \n",
       "MSE:           1.849286       47.275213         0.375936       40.035146   \n",
       "RMSE:          1.330742        5.879049         0.590369        5.234063   \n",
       "MAPE:          0.011745        0.036689         0.004880        0.031563   \n",
       "\n",
       "        Bagging Model Train  Bagging Model Test  StackedRegressor Model Train   \n",
       "R^2:               0.999168            0.530449                      0.997098  \\\n",
       "MAE:               0.278473            3.760937                      0.577446   \n",
       "MSE:               0.176833           41.980213                      0.600166   \n",
       "RMSE:              0.416253            5.356821                      0.768100   \n",
       "MAPE:              0.003075            0.033224                      0.006391   \n",
       "\n",
       "        StackedRegressor Model Test  \n",
       "R^2:                       0.983096  \n",
       "MAE:                       0.754117  \n",
       "MSE:                       0.982848  \n",
       "RMSE:                      0.982606  \n",
       "MAPE:                      0.006777  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NHY.OL\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LR Model Train</th>\n",
       "      <th>LR Model Test</th>\n",
       "      <th>DTR Model Train</th>\n",
       "      <th>DTR Model Test</th>\n",
       "      <th>MLP Model Train</th>\n",
       "      <th>MLP Model Test</th>\n",
       "      <th>XGBoost Model Train</th>\n",
       "      <th>XGBoost Model Test</th>\n",
       "      <th>XGBoost_LR Model Train</th>\n",
       "      <th>XGBoost_LR Model Test</th>\n",
       "      <th>ADA Model Train</th>\n",
       "      <th>ADA Model Test</th>\n",
       "      <th>GBR Model Train</th>\n",
       "      <th>GBR Model Test</th>\n",
       "      <th>Bagging Model Train</th>\n",
       "      <th>Bagging Model Test</th>\n",
       "      <th>StackedRegressor Model Train</th>\n",
       "      <th>StackedRegressor Model Test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>R^2:</th>\n",
       "      <td>0.997467</td>\n",
       "      <td>0.987415</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.001633</td>\n",
       "      <td>0.979465</td>\n",
       "      <td>0.958291</td>\n",
       "      <td>0.999942</td>\n",
       "      <td>0.032483</td>\n",
       "      <td>0.980248</td>\n",
       "      <td>0.832984</td>\n",
       "      <td>0.992308</td>\n",
       "      <td>-0.018220</td>\n",
       "      <td>0.998676</td>\n",
       "      <td>0.015144</td>\n",
       "      <td>0.999170</td>\n",
       "      <td>0.032348</td>\n",
       "      <td>0.997556</td>\n",
       "      <td>0.987410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MAE:</th>\n",
       "      <td>0.216049</td>\n",
       "      <td>0.502990</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.715225</td>\n",
       "      <td>0.369692</td>\n",
       "      <td>0.719381</td>\n",
       "      <td>0.037713</td>\n",
       "      <td>4.499134</td>\n",
       "      <td>0.434566</td>\n",
       "      <td>1.332363</td>\n",
       "      <td>0.431083</td>\n",
       "      <td>4.682816</td>\n",
       "      <td>0.176837</td>\n",
       "      <td>4.525284</td>\n",
       "      <td>0.107361</td>\n",
       "      <td>4.606038</td>\n",
       "      <td>0.215456</td>\n",
       "      <td>0.523171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE:</th>\n",
       "      <td>0.092438</td>\n",
       "      <td>0.505900</td>\n",
       "      <td>0.0</td>\n",
       "      <td>65.447635</td>\n",
       "      <td>0.244430</td>\n",
       "      <td>1.026624</td>\n",
       "      <td>0.004083</td>\n",
       "      <td>65.196745</td>\n",
       "      <td>0.288300</td>\n",
       "      <td>3.052542</td>\n",
       "      <td>0.321495</td>\n",
       "      <td>67.689685</td>\n",
       "      <td>0.062692</td>\n",
       "      <td>65.745855</td>\n",
       "      <td>0.027983</td>\n",
       "      <td>63.643742</td>\n",
       "      <td>0.092318</td>\n",
       "      <td>0.553801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RMSE:</th>\n",
       "      <td>0.292398</td>\n",
       "      <td>0.649690</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.082134</td>\n",
       "      <td>0.482135</td>\n",
       "      <td>0.919295</td>\n",
       "      <td>0.052920</td>\n",
       "      <td>5.811735</td>\n",
       "      <td>0.534114</td>\n",
       "      <td>1.554044</td>\n",
       "      <td>0.536984</td>\n",
       "      <td>5.988071</td>\n",
       "      <td>0.233045</td>\n",
       "      <td>5.758971</td>\n",
       "      <td>0.162365</td>\n",
       "      <td>5.952242</td>\n",
       "      <td>0.291366</td>\n",
       "      <td>0.687865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MAPE:</th>\n",
       "      <td>0.008281</td>\n",
       "      <td>0.013185</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.092884</td>\n",
       "      <td>0.015402</td>\n",
       "      <td>0.020630</td>\n",
       "      <td>0.001449</td>\n",
       "      <td>0.083906</td>\n",
       "      <td>0.018296</td>\n",
       "      <td>0.039226</td>\n",
       "      <td>0.017508</td>\n",
       "      <td>0.089250</td>\n",
       "      <td>0.006765</td>\n",
       "      <td>0.085031</td>\n",
       "      <td>0.004126</td>\n",
       "      <td>0.089760</td>\n",
       "      <td>0.008246</td>\n",
       "      <td>0.013527</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        LR Model Train  LR Model Test  DTR Model Train  DTR Model Test   \n",
       "R^2:          0.997467       0.987415              1.0        0.001633  \\\n",
       "MAE:          0.216049       0.502990              0.0        4.715225   \n",
       "MSE:          0.092438       0.505900              0.0       65.447635   \n",
       "RMSE:         0.292398       0.649690              0.0        6.082134   \n",
       "MAPE:         0.008281       0.013185              0.0        0.092884   \n",
       "\n",
       "        MLP Model Train  MLP Model Test  XGBoost Model Train   \n",
       "R^2:           0.979465        0.958291             0.999942  \\\n",
       "MAE:           0.369692        0.719381             0.037713   \n",
       "MSE:           0.244430        1.026624             0.004083   \n",
       "RMSE:          0.482135        0.919295             0.052920   \n",
       "MAPE:          0.015402        0.020630             0.001449   \n",
       "\n",
       "        XGBoost Model Test  XGBoost_LR Model Train  XGBoost_LR Model Test   \n",
       "R^2:              0.032483                0.980248               0.832984  \\\n",
       "MAE:              4.499134                0.434566               1.332363   \n",
       "MSE:             65.196745                0.288300               3.052542   \n",
       "RMSE:             5.811735                0.534114               1.554044   \n",
       "MAPE:             0.083906                0.018296               0.039226   \n",
       "\n",
       "        ADA Model Train  ADA Model Test  GBR Model Train  GBR Model Test   \n",
       "R^2:           0.992308       -0.018220         0.998676        0.015144  \\\n",
       "MAE:           0.431083        4.682816         0.176837        4.525284   \n",
       "MSE:           0.321495       67.689685         0.062692       65.745855   \n",
       "RMSE:          0.536984        5.988071         0.233045        5.758971   \n",
       "MAPE:          0.017508        0.089250         0.006765        0.085031   \n",
       "\n",
       "        Bagging Model Train  Bagging Model Test  StackedRegressor Model Train   \n",
       "R^2:               0.999170            0.032348                      0.997556  \\\n",
       "MAE:               0.107361            4.606038                      0.215456   \n",
       "MSE:               0.027983           63.643742                      0.092318   \n",
       "RMSE:              0.162365            5.952242                      0.291366   \n",
       "MAPE:              0.004126            0.089760                      0.008246   \n",
       "\n",
       "        StackedRegressor Model Test  \n",
       "R^2:                       0.987410  \n",
       "MAE:                       0.523171  \n",
       "MSE:                       0.553801  \n",
       "RMSE:                      0.687865  \n",
       "MAPE:                      0.013527  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AKRBP.OL\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LR Model Train</th>\n",
       "      <th>LR Model Test</th>\n",
       "      <th>DTR Model Train</th>\n",
       "      <th>DTR Model Test</th>\n",
       "      <th>MLP Model Train</th>\n",
       "      <th>MLP Model Test</th>\n",
       "      <th>XGBoost Model Train</th>\n",
       "      <th>XGBoost Model Test</th>\n",
       "      <th>XGBoost_LR Model Train</th>\n",
       "      <th>XGBoost_LR Model Test</th>\n",
       "      <th>ADA Model Train</th>\n",
       "      <th>ADA Model Test</th>\n",
       "      <th>GBR Model Train</th>\n",
       "      <th>GBR Model Test</th>\n",
       "      <th>Bagging Model Train</th>\n",
       "      <th>Bagging Model Test</th>\n",
       "      <th>StackedRegressor Model Train</th>\n",
       "      <th>StackedRegressor Model Test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>R^2:</th>\n",
       "      <td>0.997471</td>\n",
       "      <td>0.987651</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.173344</td>\n",
       "      <td>0.989144</td>\n",
       "      <td>0.958319</td>\n",
       "      <td>0.999974</td>\n",
       "      <td>-1.179201</td>\n",
       "      <td>0.979571</td>\n",
       "      <td>0.878016</td>\n",
       "      <td>0.992993</td>\n",
       "      <td>-1.240224</td>\n",
       "      <td>0.998899</td>\n",
       "      <td>-1.119444</td>\n",
       "      <td>0.999251</td>\n",
       "      <td>-1.321336</td>\n",
       "      <td>0.997697</td>\n",
       "      <td>0.974024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MAE:</th>\n",
       "      <td>0.792449</td>\n",
       "      <td>2.143667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>28.506369</td>\n",
       "      <td>1.112373</td>\n",
       "      <td>3.211854</td>\n",
       "      <td>0.144429</td>\n",
       "      <td>28.828296</td>\n",
       "      <td>1.639652</td>\n",
       "      <td>6.070729</td>\n",
       "      <td>1.999527</td>\n",
       "      <td>28.372468</td>\n",
       "      <td>0.626558</td>\n",
       "      <td>27.788454</td>\n",
       "      <td>0.376157</td>\n",
       "      <td>29.477289</td>\n",
       "      <td>0.769233</td>\n",
       "      <td>2.798304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE:</th>\n",
       "      <td>1.749204</td>\n",
       "      <td>10.004887</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1591.433511</td>\n",
       "      <td>3.067930</td>\n",
       "      <td>19.279097</td>\n",
       "      <td>0.066856</td>\n",
       "      <td>1657.883160</td>\n",
       "      <td>5.811785</td>\n",
       "      <td>69.131383</td>\n",
       "      <td>9.353629</td>\n",
       "      <td>1573.255916</td>\n",
       "      <td>1.038882</td>\n",
       "      <td>1527.413469</td>\n",
       "      <td>0.510305</td>\n",
       "      <td>1699.099770</td>\n",
       "      <td>1.630610</td>\n",
       "      <td>15.179106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RMSE:</th>\n",
       "      <td>1.165190</td>\n",
       "      <td>2.805306</td>\n",
       "      <td>0.0</td>\n",
       "      <td>33.927590</td>\n",
       "      <td>1.633364</td>\n",
       "      <td>4.191481</td>\n",
       "      <td>0.200391</td>\n",
       "      <td>33.816781</td>\n",
       "      <td>2.256487</td>\n",
       "      <td>7.231358</td>\n",
       "      <td>2.551002</td>\n",
       "      <td>33.831904</td>\n",
       "      <td>0.876730</td>\n",
       "      <td>32.936472</td>\n",
       "      <td>0.632009</td>\n",
       "      <td>34.784198</td>\n",
       "      <td>1.126615</td>\n",
       "      <td>3.593715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MAPE:</th>\n",
       "      <td>0.011515</td>\n",
       "      <td>0.014702</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.195520</td>\n",
       "      <td>0.016497</td>\n",
       "      <td>0.026847</td>\n",
       "      <td>0.002136</td>\n",
       "      <td>0.189457</td>\n",
       "      <td>0.027964</td>\n",
       "      <td>0.050698</td>\n",
       "      <td>0.034440</td>\n",
       "      <td>0.195748</td>\n",
       "      <td>0.008951</td>\n",
       "      <td>0.187070</td>\n",
       "      <td>0.005388</td>\n",
       "      <td>0.194583</td>\n",
       "      <td>0.011147</td>\n",
       "      <td>0.022037</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        LR Model Train  LR Model Test  DTR Model Train  DTR Model Test   \n",
       "R^2:          0.997471       0.987651              1.0       -1.173344  \\\n",
       "MAE:          0.792449       2.143667              0.0       28.506369   \n",
       "MSE:          1.749204      10.004887              0.0     1591.433511   \n",
       "RMSE:         1.165190       2.805306              0.0       33.927590   \n",
       "MAPE:         0.011515       0.014702              0.0        0.195520   \n",
       "\n",
       "        MLP Model Train  MLP Model Test  XGBoost Model Train   \n",
       "R^2:           0.989144        0.958319             0.999974  \\\n",
       "MAE:           1.112373        3.211854             0.144429   \n",
       "MSE:           3.067930       19.279097             0.066856   \n",
       "RMSE:          1.633364        4.191481             0.200391   \n",
       "MAPE:          0.016497        0.026847             0.002136   \n",
       "\n",
       "        XGBoost Model Test  XGBoost_LR Model Train  XGBoost_LR Model Test   \n",
       "R^2:             -1.179201                0.979571               0.878016  \\\n",
       "MAE:             28.828296                1.639652               6.070729   \n",
       "MSE:           1657.883160                5.811785              69.131383   \n",
       "RMSE:            33.816781                2.256487               7.231358   \n",
       "MAPE:             0.189457                0.027964               0.050698   \n",
       "\n",
       "        ADA Model Train  ADA Model Test  GBR Model Train  GBR Model Test   \n",
       "R^2:           0.992993       -1.240224         0.998899       -1.119444  \\\n",
       "MAE:           1.999527       28.372468         0.626558       27.788454   \n",
       "MSE:           9.353629     1573.255916         1.038882     1527.413469   \n",
       "RMSE:          2.551002       33.831904         0.876730       32.936472   \n",
       "MAPE:          0.034440        0.195748         0.008951        0.187070   \n",
       "\n",
       "        Bagging Model Train  Bagging Model Test  StackedRegressor Model Train   \n",
       "R^2:               0.999251           -1.321336                      0.997697  \\\n",
       "MAE:               0.376157           29.477289                      0.769233   \n",
       "MSE:               0.510305         1699.099770                      1.630610   \n",
       "RMSE:              0.632009           34.784198                      1.126615   \n",
       "MAPE:              0.005388            0.194583                      0.011147   \n",
       "\n",
       "        StackedRegressor Model Test  \n",
       "R^2:                       0.974024  \n",
       "MAE:                       2.798304  \n",
       "MSE:                      15.179106  \n",
       "RMSE:                      3.593715  \n",
       "MAPE:                      0.022037  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YAR.OL\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LR Model Train</th>\n",
       "      <th>LR Model Test</th>\n",
       "      <th>DTR Model Train</th>\n",
       "      <th>DTR Model Test</th>\n",
       "      <th>MLP Model Train</th>\n",
       "      <th>MLP Model Test</th>\n",
       "      <th>XGBoost Model Train</th>\n",
       "      <th>XGBoost Model Test</th>\n",
       "      <th>XGBoost_LR Model Train</th>\n",
       "      <th>XGBoost_LR Model Test</th>\n",
       "      <th>ADA Model Train</th>\n",
       "      <th>ADA Model Test</th>\n",
       "      <th>GBR Model Train</th>\n",
       "      <th>GBR Model Test</th>\n",
       "      <th>Bagging Model Train</th>\n",
       "      <th>Bagging Model Test</th>\n",
       "      <th>StackedRegressor Model Train</th>\n",
       "      <th>StackedRegressor Model Test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>R^2:</th>\n",
       "      <td>0.995745</td>\n",
       "      <td>0.983010</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.016135</td>\n",
       "      <td>0.978203</td>\n",
       "      <td>0.960703</td>\n",
       "      <td>0.999909</td>\n",
       "      <td>-0.007071</td>\n",
       "      <td>0.961541</td>\n",
       "      <td>0.655861</td>\n",
       "      <td>0.990474</td>\n",
       "      <td>-0.031936</td>\n",
       "      <td>0.997809</td>\n",
       "      <td>0.070790</td>\n",
       "      <td>0.998730</td>\n",
       "      <td>0.045047</td>\n",
       "      <td>0.995412</td>\n",
       "      <td>0.977786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MAE:</th>\n",
       "      <td>1.563545</td>\n",
       "      <td>2.820176</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.143209</td>\n",
       "      <td>2.648010</td>\n",
       "      <td>4.275038</td>\n",
       "      <td>0.278150</td>\n",
       "      <td>19.340437</td>\n",
       "      <td>4.102428</td>\n",
       "      <td>11.252370</td>\n",
       "      <td>2.712470</td>\n",
       "      <td>19.839430</td>\n",
       "      <td>1.254311</td>\n",
       "      <td>18.231405</td>\n",
       "      <td>0.766314</td>\n",
       "      <td>18.561577</td>\n",
       "      <td>1.588073</td>\n",
       "      <td>3.184701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE:</th>\n",
       "      <td>4.346831</td>\n",
       "      <td>14.057960</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1090.942853</td>\n",
       "      <td>11.492002</td>\n",
       "      <td>31.804501</td>\n",
       "      <td>0.205592</td>\n",
       "      <td>1068.602849</td>\n",
       "      <td>26.861801</td>\n",
       "      <td>292.556698</td>\n",
       "      <td>12.519057</td>\n",
       "      <td>1047.805089</td>\n",
       "      <td>2.898339</td>\n",
       "      <td>958.608659</td>\n",
       "      <td>1.263751</td>\n",
       "      <td>988.295989</td>\n",
       "      <td>4.474987</td>\n",
       "      <td>18.346529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RMSE:</th>\n",
       "      <td>2.038675</td>\n",
       "      <td>3.610949</td>\n",
       "      <td>0.0</td>\n",
       "      <td>27.888699</td>\n",
       "      <td>3.373558</td>\n",
       "      <td>5.380367</td>\n",
       "      <td>0.385528</td>\n",
       "      <td>27.206476</td>\n",
       "      <td>5.145519</td>\n",
       "      <td>13.377806</td>\n",
       "      <td>3.390294</td>\n",
       "      <td>27.326063</td>\n",
       "      <td>1.623027</td>\n",
       "      <td>25.618995</td>\n",
       "      <td>1.102195</td>\n",
       "      <td>25.837961</td>\n",
       "      <td>2.072681</td>\n",
       "      <td>4.026311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MAPE:</th>\n",
       "      <td>0.007311</td>\n",
       "      <td>0.009782</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.066625</td>\n",
       "      <td>0.012813</td>\n",
       "      <td>0.014967</td>\n",
       "      <td>0.001285</td>\n",
       "      <td>0.062821</td>\n",
       "      <td>0.020639</td>\n",
       "      <td>0.041348</td>\n",
       "      <td>0.013115</td>\n",
       "      <td>0.064975</td>\n",
       "      <td>0.005838</td>\n",
       "      <td>0.059766</td>\n",
       "      <td>0.003580</td>\n",
       "      <td>0.061318</td>\n",
       "      <td>0.007434</td>\n",
       "      <td>0.011185</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        LR Model Train  LR Model Test  DTR Model Train  DTR Model Test   \n",
       "R^2:          0.995745       0.983010              1.0       -0.016135  \\\n",
       "MAE:          1.563545       2.820176              0.0       20.143209   \n",
       "MSE:          4.346831      14.057960              0.0     1090.942853   \n",
       "RMSE:         2.038675       3.610949              0.0       27.888699   \n",
       "MAPE:         0.007311       0.009782              0.0        0.066625   \n",
       "\n",
       "        MLP Model Train  MLP Model Test  XGBoost Model Train   \n",
       "R^2:           0.978203        0.960703             0.999909  \\\n",
       "MAE:           2.648010        4.275038             0.278150   \n",
       "MSE:          11.492002       31.804501             0.205592   \n",
       "RMSE:          3.373558        5.380367             0.385528   \n",
       "MAPE:          0.012813        0.014967             0.001285   \n",
       "\n",
       "        XGBoost Model Test  XGBoost_LR Model Train  XGBoost_LR Model Test   \n",
       "R^2:             -0.007071                0.961541               0.655861  \\\n",
       "MAE:             19.340437                4.102428              11.252370   \n",
       "MSE:           1068.602849               26.861801             292.556698   \n",
       "RMSE:            27.206476                5.145519              13.377806   \n",
       "MAPE:             0.062821                0.020639               0.041348   \n",
       "\n",
       "        ADA Model Train  ADA Model Test  GBR Model Train  GBR Model Test   \n",
       "R^2:           0.990474       -0.031936         0.997809        0.070790  \\\n",
       "MAE:           2.712470       19.839430         1.254311       18.231405   \n",
       "MSE:          12.519057     1047.805089         2.898339      958.608659   \n",
       "RMSE:          3.390294       27.326063         1.623027       25.618995   \n",
       "MAPE:          0.013115        0.064975         0.005838        0.059766   \n",
       "\n",
       "        Bagging Model Train  Bagging Model Test  StackedRegressor Model Train   \n",
       "R^2:               0.998730            0.045047                      0.995412  \\\n",
       "MAE:               0.766314           18.561577                      1.588073   \n",
       "MSE:               1.263751          988.295989                      4.474987   \n",
       "RMSE:              1.102195           25.837961                      2.072681   \n",
       "MAPE:              0.003580            0.061318                      0.007434   \n",
       "\n",
       "        StackedRegressor Model Test  \n",
       "R^2:                       0.977786  \n",
       "MAE:                       3.184701  \n",
       "MSE:                      18.346529  \n",
       "RMSE:                      4.026311  \n",
       "MAPE:                      0.011185  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MOWI.OL\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LR Model Train</th>\n",
       "      <th>LR Model Test</th>\n",
       "      <th>DTR Model Train</th>\n",
       "      <th>DTR Model Test</th>\n",
       "      <th>MLP Model Train</th>\n",
       "      <th>MLP Model Test</th>\n",
       "      <th>XGBoost Model Train</th>\n",
       "      <th>XGBoost Model Test</th>\n",
       "      <th>XGBoost_LR Model Train</th>\n",
       "      <th>XGBoost_LR Model Test</th>\n",
       "      <th>ADA Model Train</th>\n",
       "      <th>ADA Model Test</th>\n",
       "      <th>GBR Model Train</th>\n",
       "      <th>GBR Model Test</th>\n",
       "      <th>Bagging Model Train</th>\n",
       "      <th>Bagging Model Test</th>\n",
       "      <th>StackedRegressor Model Train</th>\n",
       "      <th>StackedRegressor Model Test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>R^2:</th>\n",
       "      <td>0.998952</td>\n",
       "      <td>0.990506</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.839472</td>\n",
       "      <td>0.988862</td>\n",
       "      <td>0.968156</td>\n",
       "      <td>0.999981</td>\n",
       "      <td>-1.231077</td>\n",
       "      <td>0.992089</td>\n",
       "      <td>0.922960</td>\n",
       "      <td>0.995671</td>\n",
       "      <td>-1.336703</td>\n",
       "      <td>0.999517</td>\n",
       "      <td>-1.140787</td>\n",
       "      <td>0.999649</td>\n",
       "      <td>-1.144605</td>\n",
       "      <td>0.998741</td>\n",
       "      <td>0.989415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MAE:</th>\n",
       "      <td>0.638998</td>\n",
       "      <td>1.288049</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.824719</td>\n",
       "      <td>1.133521</td>\n",
       "      <td>2.279128</td>\n",
       "      <td>0.119343</td>\n",
       "      <td>15.946646</td>\n",
       "      <td>1.399639</td>\n",
       "      <td>3.246322</td>\n",
       "      <td>1.669670</td>\n",
       "      <td>16.328259</td>\n",
       "      <td>0.510020</td>\n",
       "      <td>15.211037</td>\n",
       "      <td>0.306631</td>\n",
       "      <td>15.224386</td>\n",
       "      <td>0.654097</td>\n",
       "      <td>1.333954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE:</th>\n",
       "      <td>0.895393</td>\n",
       "      <td>3.204626</td>\n",
       "      <td>0.0</td>\n",
       "      <td>544.750930</td>\n",
       "      <td>2.635649</td>\n",
       "      <td>9.303142</td>\n",
       "      <td>0.042872</td>\n",
       "      <td>517.692688</td>\n",
       "      <td>3.412336</td>\n",
       "      <td>17.106117</td>\n",
       "      <td>5.771571</td>\n",
       "      <td>534.368429</td>\n",
       "      <td>0.585606</td>\n",
       "      <td>482.974193</td>\n",
       "      <td>0.245824</td>\n",
       "      <td>492.101659</td>\n",
       "      <td>0.916591</td>\n",
       "      <td>3.349062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RMSE:</th>\n",
       "      <td>0.881441</td>\n",
       "      <td>1.688602</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19.943286</td>\n",
       "      <td>1.536275</td>\n",
       "      <td>2.898530</td>\n",
       "      <td>0.165680</td>\n",
       "      <td>19.220786</td>\n",
       "      <td>1.789781</td>\n",
       "      <td>3.981474</td>\n",
       "      <td>2.114815</td>\n",
       "      <td>19.584958</td>\n",
       "      <td>0.686433</td>\n",
       "      <td>18.476414</td>\n",
       "      <td>0.469815</td>\n",
       "      <td>18.482437</td>\n",
       "      <td>0.901027</td>\n",
       "      <td>1.750849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MAPE:</th>\n",
       "      <td>0.008083</td>\n",
       "      <td>0.008576</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.123415</td>\n",
       "      <td>0.015487</td>\n",
       "      <td>0.017040</td>\n",
       "      <td>0.001468</td>\n",
       "      <td>0.113480</td>\n",
       "      <td>0.021246</td>\n",
       "      <td>0.026051</td>\n",
       "      <td>0.025576</td>\n",
       "      <td>0.117837</td>\n",
       "      <td>0.006153</td>\n",
       "      <td>0.110186</td>\n",
       "      <td>0.003812</td>\n",
       "      <td>0.110084</td>\n",
       "      <td>0.008363</td>\n",
       "      <td>0.009041</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        LR Model Train  LR Model Test  DTR Model Train  DTR Model Test   \n",
       "R^2:          0.998952       0.990506              1.0       -1.839472  \\\n",
       "MAE:          0.638998       1.288049              0.0       16.824719   \n",
       "MSE:          0.895393       3.204626              0.0      544.750930   \n",
       "RMSE:         0.881441       1.688602              0.0       19.943286   \n",
       "MAPE:         0.008083       0.008576              0.0        0.123415   \n",
       "\n",
       "        MLP Model Train  MLP Model Test  XGBoost Model Train   \n",
       "R^2:           0.988862        0.968156             0.999981  \\\n",
       "MAE:           1.133521        2.279128             0.119343   \n",
       "MSE:           2.635649        9.303142             0.042872   \n",
       "RMSE:          1.536275        2.898530             0.165680   \n",
       "MAPE:          0.015487        0.017040             0.001468   \n",
       "\n",
       "        XGBoost Model Test  XGBoost_LR Model Train  XGBoost_LR Model Test   \n",
       "R^2:             -1.231077                0.992089               0.922960  \\\n",
       "MAE:             15.946646                1.399639               3.246322   \n",
       "MSE:            517.692688                3.412336              17.106117   \n",
       "RMSE:            19.220786                1.789781               3.981474   \n",
       "MAPE:             0.113480                0.021246               0.026051   \n",
       "\n",
       "        ADA Model Train  ADA Model Test  GBR Model Train  GBR Model Test   \n",
       "R^2:           0.995671       -1.336703         0.999517       -1.140787  \\\n",
       "MAE:           1.669670       16.328259         0.510020       15.211037   \n",
       "MSE:           5.771571      534.368429         0.585606      482.974193   \n",
       "RMSE:          2.114815       19.584958         0.686433       18.476414   \n",
       "MAPE:          0.025576        0.117837         0.006153        0.110186   \n",
       "\n",
       "        Bagging Model Train  Bagging Model Test  StackedRegressor Model Train   \n",
       "R^2:               0.999649           -1.144605                      0.998741  \\\n",
       "MAE:               0.306631           15.224386                      0.654097   \n",
       "MSE:               0.245824          492.101659                      0.916591   \n",
       "RMSE:              0.469815           18.482437                      0.901027   \n",
       "MAPE:              0.003812            0.110084                      0.008363   \n",
       "\n",
       "        StackedRegressor Model Test  \n",
       "R^2:                       0.989415  \n",
       "MAE:                       1.333954  \n",
       "MSE:                       3.349062  \n",
       "RMSE:                      1.750849  \n",
       "MAPE:                      0.009041  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CL=F\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LR Model Train</th>\n",
       "      <th>LR Model Test</th>\n",
       "      <th>DTR Model Train</th>\n",
       "      <th>DTR Model Test</th>\n",
       "      <th>MLP Model Train</th>\n",
       "      <th>MLP Model Test</th>\n",
       "      <th>XGBoost Model Train</th>\n",
       "      <th>XGBoost Model Test</th>\n",
       "      <th>XGBoost_LR Model Train</th>\n",
       "      <th>XGBoost_LR Model Test</th>\n",
       "      <th>ADA Model Train</th>\n",
       "      <th>ADA Model Test</th>\n",
       "      <th>GBR Model Train</th>\n",
       "      <th>GBR Model Test</th>\n",
       "      <th>Bagging Model Train</th>\n",
       "      <th>Bagging Model Test</th>\n",
       "      <th>StackedRegressor Model Train</th>\n",
       "      <th>StackedRegressor Model Test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>R^2:</th>\n",
       "      <td>0.996575</td>\n",
       "      <td>0.987903</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.129621</td>\n",
       "      <td>0.982882</td>\n",
       "      <td>0.979212</td>\n",
       "      <td>0.999959</td>\n",
       "      <td>0.280338</td>\n",
       "      <td>0.963190</td>\n",
       "      <td>0.462852</td>\n",
       "      <td>0.991886</td>\n",
       "      <td>0.180349</td>\n",
       "      <td>0.998569</td>\n",
       "      <td>0.233707</td>\n",
       "      <td>0.998896</td>\n",
       "      <td>0.192584</td>\n",
       "      <td>0.996882</td>\n",
       "      <td>0.986949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MAE:</th>\n",
       "      <td>0.575141</td>\n",
       "      <td>0.856079</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.464470</td>\n",
       "      <td>0.840873</td>\n",
       "      <td>1.237754</td>\n",
       "      <td>0.089111</td>\n",
       "      <td>7.554537</td>\n",
       "      <td>1.615894</td>\n",
       "      <td>4.674823</td>\n",
       "      <td>1.060319</td>\n",
       "      <td>8.380880</td>\n",
       "      <td>0.448366</td>\n",
       "      <td>7.717834</td>\n",
       "      <td>0.285155</td>\n",
       "      <td>8.076862</td>\n",
       "      <td>0.545760</td>\n",
       "      <td>0.960926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE:</th>\n",
       "      <td>0.545862</td>\n",
       "      <td>1.554690</td>\n",
       "      <td>0.0</td>\n",
       "      <td>297.042538</td>\n",
       "      <td>1.221928</td>\n",
       "      <td>3.165144</td>\n",
       "      <td>0.019427</td>\n",
       "      <td>260.902947</td>\n",
       "      <td>4.370454</td>\n",
       "      <td>47.124390</td>\n",
       "      <td>1.725674</td>\n",
       "      <td>283.861814</td>\n",
       "      <td>0.326660</td>\n",
       "      <td>280.745720</td>\n",
       "      <td>0.158959</td>\n",
       "      <td>284.523953</td>\n",
       "      <td>0.492240</td>\n",
       "      <td>1.966455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RMSE:</th>\n",
       "      <td>0.738008</td>\n",
       "      <td>1.153589</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.027757</td>\n",
       "      <td>1.056359</td>\n",
       "      <td>1.580250</td>\n",
       "      <td>0.122525</td>\n",
       "      <td>8.922371</td>\n",
       "      <td>2.052797</td>\n",
       "      <td>5.862376</td>\n",
       "      <td>1.302739</td>\n",
       "      <td>9.903212</td>\n",
       "      <td>0.563966</td>\n",
       "      <td>9.143775</td>\n",
       "      <td>0.398350</td>\n",
       "      <td>9.549923</td>\n",
       "      <td>0.700607</td>\n",
       "      <td>1.260132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MAPE:</th>\n",
       "      <td>0.009054</td>\n",
       "      <td>0.015343</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.184940</td>\n",
       "      <td>0.012319</td>\n",
       "      <td>0.021960</td>\n",
       "      <td>0.001464</td>\n",
       "      <td>0.167498</td>\n",
       "      <td>0.026410</td>\n",
       "      <td>0.099569</td>\n",
       "      <td>0.016861</td>\n",
       "      <td>0.181413</td>\n",
       "      <td>0.007076</td>\n",
       "      <td>0.171894</td>\n",
       "      <td>0.004492</td>\n",
       "      <td>0.177457</td>\n",
       "      <td>0.008556</td>\n",
       "      <td>0.017739</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        LR Model Train  LR Model Test  DTR Model Train  DTR Model Test   \n",
       "R^2:          0.996575       0.987903              1.0        0.129621  \\\n",
       "MAE:          0.575141       0.856079              0.0        8.464470   \n",
       "MSE:          0.545862       1.554690              0.0      297.042538   \n",
       "RMSE:         0.738008       1.153589              0.0       10.027757   \n",
       "MAPE:         0.009054       0.015343              0.0        0.184940   \n",
       "\n",
       "        MLP Model Train  MLP Model Test  XGBoost Model Train   \n",
       "R^2:           0.982882        0.979212             0.999959  \\\n",
       "MAE:           0.840873        1.237754             0.089111   \n",
       "MSE:           1.221928        3.165144             0.019427   \n",
       "RMSE:          1.056359        1.580250             0.122525   \n",
       "MAPE:          0.012319        0.021960             0.001464   \n",
       "\n",
       "        XGBoost Model Test  XGBoost_LR Model Train  XGBoost_LR Model Test   \n",
       "R^2:              0.280338                0.963190               0.462852  \\\n",
       "MAE:              7.554537                1.615894               4.674823   \n",
       "MSE:            260.902947                4.370454              47.124390   \n",
       "RMSE:             8.922371                2.052797               5.862376   \n",
       "MAPE:             0.167498                0.026410               0.099569   \n",
       "\n",
       "        ADA Model Train  ADA Model Test  GBR Model Train  GBR Model Test   \n",
       "R^2:           0.991886        0.180349         0.998569        0.233707  \\\n",
       "MAE:           1.060319        8.380880         0.448366        7.717834   \n",
       "MSE:           1.725674      283.861814         0.326660      280.745720   \n",
       "RMSE:          1.302739        9.903212         0.563966        9.143775   \n",
       "MAPE:          0.016861        0.181413         0.007076        0.171894   \n",
       "\n",
       "        Bagging Model Train  Bagging Model Test  StackedRegressor Model Train   \n",
       "R^2:               0.998896            0.192584                      0.996882  \\\n",
       "MAE:               0.285155            8.076862                      0.545760   \n",
       "MSE:               0.158959          284.523953                      0.492240   \n",
       "RMSE:              0.398350            9.549923                      0.700607   \n",
       "MAPE:              0.004492            0.177457                      0.008556   \n",
       "\n",
       "        StackedRegressor Model Test  \n",
       "R^2:                       0.986949  \n",
       "MAE:                       0.960926  \n",
       "MSE:                       1.966455  \n",
       "RMSE:                      1.260132  \n",
       "MAPE:                      0.017739  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OSEBX.OL\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LR Model Train</th>\n",
       "      <th>LR Model Test</th>\n",
       "      <th>DTR Model Train</th>\n",
       "      <th>DTR Model Test</th>\n",
       "      <th>MLP Model Train</th>\n",
       "      <th>MLP Model Test</th>\n",
       "      <th>XGBoost Model Train</th>\n",
       "      <th>XGBoost Model Test</th>\n",
       "      <th>XGBoost_LR Model Train</th>\n",
       "      <th>XGBoost_LR Model Test</th>\n",
       "      <th>ADA Model Train</th>\n",
       "      <th>ADA Model Test</th>\n",
       "      <th>GBR Model Train</th>\n",
       "      <th>GBR Model Test</th>\n",
       "      <th>Bagging Model Train</th>\n",
       "      <th>Bagging Model Test</th>\n",
       "      <th>StackedRegressor Model Train</th>\n",
       "      <th>StackedRegressor Model Test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>R^2:</th>\n",
       "      <td>0.994848</td>\n",
       "      <td>0.979712</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.125176</td>\n",
       "      <td>0.820841</td>\n",
       "      <td>0.776224</td>\n",
       "      <td>0.999962</td>\n",
       "      <td>0.156037</td>\n",
       "      <td>0.911728</td>\n",
       "      <td>0.323643</td>\n",
       "      <td>0.988226</td>\n",
       "      <td>-0.250857</td>\n",
       "      <td>0.997741</td>\n",
       "      <td>0.129419</td>\n",
       "      <td>0.998428</td>\n",
       "      <td>0.167747</td>\n",
       "      <td>0.995239</td>\n",
       "      <td>0.979147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MAE:</th>\n",
       "      <td>3.163232</td>\n",
       "      <td>4.788909</td>\n",
       "      <td>0.0</td>\n",
       "      <td>44.864994</td>\n",
       "      <td>10.663121</td>\n",
       "      <td>14.103808</td>\n",
       "      <td>0.439403</td>\n",
       "      <td>43.684256</td>\n",
       "      <td>14.501346</td>\n",
       "      <td>41.679637</td>\n",
       "      <td>6.173987</td>\n",
       "      <td>53.017135</td>\n",
       "      <td>2.454449</td>\n",
       "      <td>43.827614</td>\n",
       "      <td>1.562857</td>\n",
       "      <td>43.333654</td>\n",
       "      <td>3.092078</td>\n",
       "      <td>4.799669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE:</th>\n",
       "      <td>17.624453</td>\n",
       "      <td>43.234834</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5719.018999</td>\n",
       "      <td>240.674259</td>\n",
       "      <td>396.297767</td>\n",
       "      <td>0.548877</td>\n",
       "      <td>5953.288481</td>\n",
       "      <td>321.697051</td>\n",
       "      <td>2531.948640</td>\n",
       "      <td>64.197117</td>\n",
       "      <td>6927.159022</td>\n",
       "      <td>10.599083</td>\n",
       "      <td>5850.139278</td>\n",
       "      <td>5.710568</td>\n",
       "      <td>5591.893622</td>\n",
       "      <td>17.114569</td>\n",
       "      <td>44.461639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RMSE:</th>\n",
       "      <td>4.162509</td>\n",
       "      <td>6.329614</td>\n",
       "      <td>0.0</td>\n",
       "      <td>59.851689</td>\n",
       "      <td>12.715524</td>\n",
       "      <td>17.029071</td>\n",
       "      <td>0.607344</td>\n",
       "      <td>59.713119</td>\n",
       "      <td>17.702334</td>\n",
       "      <td>45.634958</td>\n",
       "      <td>7.667849</td>\n",
       "      <td>68.623445</td>\n",
       "      <td>3.145412</td>\n",
       "      <td>59.989699</td>\n",
       "      <td>2.364190</td>\n",
       "      <td>58.848024</td>\n",
       "      <td>4.088779</td>\n",
       "      <td>6.426422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MAPE:</th>\n",
       "      <td>0.004804</td>\n",
       "      <td>0.005503</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.047953</td>\n",
       "      <td>0.017121</td>\n",
       "      <td>0.019347</td>\n",
       "      <td>0.000632</td>\n",
       "      <td>0.046523</td>\n",
       "      <td>0.022299</td>\n",
       "      <td>0.047157</td>\n",
       "      <td>0.009242</td>\n",
       "      <td>0.055653</td>\n",
       "      <td>0.003675</td>\n",
       "      <td>0.046529</td>\n",
       "      <td>0.002368</td>\n",
       "      <td>0.046238</td>\n",
       "      <td>0.004689</td>\n",
       "      <td>0.005541</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        LR Model Train  LR Model Test  DTR Model Train  DTR Model Test   \n",
       "R^2:          0.994848       0.979712              1.0        0.125176  \\\n",
       "MAE:          3.163232       4.788909              0.0       44.864994   \n",
       "MSE:         17.624453      43.234834              0.0     5719.018999   \n",
       "RMSE:         4.162509       6.329614              0.0       59.851689   \n",
       "MAPE:         0.004804       0.005503              0.0        0.047953   \n",
       "\n",
       "        MLP Model Train  MLP Model Test  XGBoost Model Train   \n",
       "R^2:           0.820841        0.776224             0.999962  \\\n",
       "MAE:          10.663121       14.103808             0.439403   \n",
       "MSE:         240.674259      396.297767             0.548877   \n",
       "RMSE:         12.715524       17.029071             0.607344   \n",
       "MAPE:          0.017121        0.019347             0.000632   \n",
       "\n",
       "        XGBoost Model Test  XGBoost_LR Model Train  XGBoost_LR Model Test   \n",
       "R^2:              0.156037                0.911728               0.323643  \\\n",
       "MAE:             43.684256               14.501346              41.679637   \n",
       "MSE:           5953.288481              321.697051            2531.948640   \n",
       "RMSE:            59.713119               17.702334              45.634958   \n",
       "MAPE:             0.046523                0.022299               0.047157   \n",
       "\n",
       "        ADA Model Train  ADA Model Test  GBR Model Train  GBR Model Test   \n",
       "R^2:           0.988226       -0.250857         0.997741        0.129419  \\\n",
       "MAE:           6.173987       53.017135         2.454449       43.827614   \n",
       "MSE:          64.197117     6927.159022        10.599083     5850.139278   \n",
       "RMSE:          7.667849       68.623445         3.145412       59.989699   \n",
       "MAPE:          0.009242        0.055653         0.003675        0.046529   \n",
       "\n",
       "        Bagging Model Train  Bagging Model Test  StackedRegressor Model Train   \n",
       "R^2:               0.998428            0.167747                      0.995239  \\\n",
       "MAE:               1.562857           43.333654                      3.092078   \n",
       "MSE:               5.710568         5591.893622                     17.114569   \n",
       "RMSE:              2.364190           58.848024                      4.088779   \n",
       "MAPE:              0.002368            0.046238                      0.004689   \n",
       "\n",
       "        StackedRegressor Model Test  \n",
       "R^2:                       0.979147  \n",
       "MAE:                       4.799669  \n",
       "MSE:                      44.461639  \n",
       "RMSE:                      6.426422  \n",
       "MAPE:                      0.005541  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for ticker in stocks_list:\n",
    "    print(ticker)\n",
    "    display(metrics_output[ticker])\n",
    "    #metrics_output[ticker].to_csv(\"saved_metrics/stock_\"+ticker+\".csv\")\n",
    "    #stock_data[ticker].to_pickle(\"saved_data_pickle/stock_\"+ticker+\".pkl\")\n",
    "    predicted_stock_data[ticker].to_csv(\"saved_predictions/_\"+ticker+\".csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.11 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
