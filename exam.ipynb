{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Models import ML_Models\n",
    "exam_models = ML_Models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "import numpy as np\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.model_selection import cross_validate\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters used for fetching the data from yfinance.\n",
    "start_date = \"2012-01-01\"\n",
    "end_date = dt.date.today()\n",
    "main_col = \"Adj Close\"\n",
    "interval = \"1d\"\n",
    "stocks_list = [\"EQNR.OL\", \"DNB.OL\", \"TEL.OL\", \"NHY.OL\", \"AKRBP.OL\", \"YAR.OL\", \"MOWI.OL\", \"BZ=F\", \"OSEBX.OL\"]\n",
    "\n",
    "# Specifying the indicators wanted for further analysis.\n",
    "indicators = [\"MA5\", \"MA20\", \"MA50\", \"MA200\", \"MIN\", \"MAX\", \"LOG_RET\", \"MOM\", \"VOLA\", \"DIFF\"]\n",
    "\n",
    "# Models to utilize for forecasting/prediction. \n",
    "# Name of the models are based on the pick_model function in Models.py\n",
    "models = [\"LR\", \"DTR\", \"MLP\", \"XGBoost\", \"XGBoost_LR\", \"ADA\", \"ADA_LR\", \"GBR\", \"Bagging\", \"Bagging_LR\", \"Bagging_MLP\", \"StackedRegressor\"]\n",
    "\n",
    "# Metrics used to evaluate the performance of each model.\n",
    "# MAE, MSE, RMSE and MAPE are named with \"neg_\" to be recognized by the cross_validate function from scikit-learn.\n",
    "metric_names = [\"r2\", \"neg_mean_absolute_error\", \"neg_mean_squared_error\", \"neg_root_mean_squared_error\", \"neg_mean_absolute_percentage_error\"]\n",
    "pretty_metric_names = {\"r2\":\"R^2: \", \"neg_mean_absolute_error\":\"MAE: \", \"neg_mean_squared_error\":\"MSE: \",\"neg_root_mean_squared_error\":\"RMSE: \", \"neg_mean_absolute_percentage_error\":\"MAPE: \"}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collecting data from Yahoo Finance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stock_data = {}\n",
    "for ticker in stocks_list:\n",
    "    print(f\"Downloading {ticker} data\")\n",
    "    # fetch stock data from yahoo finance\n",
    "    raw_data = yf.download(ticker, start=start_date, end=end_date, interval=interval)\n",
    "    stock_data[ticker] = raw_data\n",
    "\n",
    "print(\"All the data is now downloaded!\")\n",
    "\n",
    "# Save fetched data to csv\n",
    "#for ticker in stocks_list:\n",
    "#    stock_data[ticker].to_csv(\"raw_data/data_\"+ticker+\".csv\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preproccesing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_indicator_columns(data, indicators):\n",
    "    # Creating label and shifting the selected main_col value by 1.\n",
    "    label_name = \"Label\"\n",
    "    data[label_name] = data[main_col].shift(periods=1)\n",
    "\n",
    "    # Checking which of the different indicators that should be added as a column (based on input from indicators list).\n",
    "    if \"MA5\" in indicators:\n",
    "        data[\"MA5\"] = data[label_name].rolling(5).mean()\n",
    "    if \"MA20\" in indicators:\n",
    "        data[\"MA20\"] = data[label_name].rolling(20).mean()\n",
    "    if \"MA50\" in indicators:\n",
    "        data[\"MA50\"] = data[label_name].rolling(50).mean()\n",
    "    if \"MA200\" in indicators:\n",
    "        data[\"MA200\"] = data[label_name].rolling(200).mean()\n",
    "    if \"MIN\" in indicators:\n",
    "        data[\"MIN\"] = data[label_name].rolling(20).min()\n",
    "    if \"MAX\" in indicators:\n",
    "        data[\"MAX\"] = data[label_name].rolling(20).max()\n",
    "    log_ret = np.log(data[label_name] / data[label_name].shift(1))\n",
    "    if \"LOG_RET\" in indicators:\n",
    "        data[\"LOG_RET\"] = log_ret\n",
    "    if \"MOM\" in indicators:\n",
    "        data[\"MOM\"] = log_ret.rolling(20).mean()\n",
    "    if \"VOLA\" in indicators:\n",
    "        data[\"VOLA\"] = log_ret.rolling(20).std()\n",
    "    if \"DIFF\" in indicators:\n",
    "        data[\"DIFF\"] = data[label_name] - data[label_name].shift(1)\n",
    "\n",
    "    # remove empty vals.\n",
    "    data.dropna(axis=0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_X_y_arrays(data, label_name):\n",
    "        # array that contains the indicators data.\n",
    "        X = data.loc[:, indicators].to_numpy()\n",
    "        # array with the target data (based on main_col).\n",
    "        y = data[label_name].to_numpy()\n",
    "        return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_splits = 5\n",
    "tscv = TimeSeriesSplit(n_splits=n_splits)\n",
    "\n",
    "def create_X_y_train_test_split(X, y, current_stock):\n",
    "    data = stock_data[current_stock]\n",
    "\n",
    "    for train_index, test_index in tscv.split(data):\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding the specified indicators to the data.\n",
    "for ticker, data in stock_data.items():\n",
    "    add_indicator_columns(data=data, indicators=indicators)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_results = {}\n",
    "trained_models = {}\n",
    "\n",
    "# THIS FUNCTION CAN HAVE HIGH RUNTIME BASED ON THE AMOUNT OF MODELS AND DATA.\n",
    "# INPUT MUST BE A LIST.\n",
    "def train_models(input_models):\n",
    "        for ticker, data in stock_data.items():\n",
    "\n",
    "            X, y = create_X_y_arrays(data=data, label_name=\"Label\")\n",
    "\n",
    "            X_train, X_test, y_train, y_test = create_X_y_train_test_split(X=X, y=y, current_stock=ticker)\n",
    "\n",
    "            # Evaluating and training selected models.\n",
    "            for model_i in input_models:\n",
    "                model = exam_models.pick_model(model=model_i)\n",
    "                metric_dict = {}\n",
    "                for metric_name in metric_names:\n",
    "                    metric_dict[metric_name] = metric_name\n",
    "\n",
    "                # using method from sci-kit lib to cross-validate\n",
    "                cross_val_results = cross_validate(\n",
    "                    model,\n",
    "                    X,\n",
    "                    y,\n",
    "                    cv=tscv,\n",
    "                    scoring=metric_dict,\n",
    "                    return_train_score=True,\n",
    "                    n_jobs=-1,\n",
    "                    verbose=0  \n",
    "                )\n",
    "                model.fit(X_train, y_train)\n",
    "                cv_results[ticker+\"_model_\"+model_i] = cross_val_results \n",
    "                trained_models[\"trained_model_\"+model_i+\"_\"+ticker] = model\n",
    "\n",
    "        return cv_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_stocks_models = train_models(input_models=models)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting values based on trained models "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stock_predictions = {}\n",
    "def predict_trained_models(input_models):\n",
    "    for ticker, data in stock_data.items():\n",
    "\n",
    "        # Creating X and y arrays for train and test sets.\n",
    "        X, y = create_X_y_arrays(data=data, label_name= \"Label\")\n",
    "\n",
    "        X_train, X_test, y_train, y_test = create_X_y_train_test_split(X=X, y=y, current_stock=ticker)\n",
    "\n",
    "        last_train_index, last_test_index = None, None\n",
    "\n",
    "        for train_index, test_index in tscv.split(data):\n",
    "            last_train_index, last_test_index = train_index, test_index\n",
    "\n",
    "        prediction = data.loc[data.index[last_test_index], [main_col]].copy(deep=True)\n",
    "        stock_predictions[ticker] = prediction\n",
    "\n",
    "        for model_i in input_models:\n",
    "            model = trained_models[\"trained_model_\"+model_i+\"_\"+ticker]\n",
    "            y_pred = model.predict(X_test)\n",
    "            prediction.loc[:, model_i+\" Prediction\"] = y_pred\n",
    "\n",
    "    return stock_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_stock_data = predict_trained_models(input_models=models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ticker in stocks_list:\n",
    "    print(ticker)\n",
    "    display(predicted_stock_data[ticker])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_calculated_metrics():\n",
    "    metrics_df_output_new = {}\n",
    "\n",
    "    for ticker in stocks_list:\n",
    "        print(ticker)\n",
    "\n",
    "        metrics_df = pd.DataFrame(index=list(pretty_metric_names.values()))\n",
    "        metrics_df_output_new[ticker] = metrics_df\n",
    "\n",
    "        for model_name in models:\n",
    "            res = cv_results[ticker+\"_model_\"+model_name]\n",
    "\n",
    "            print(\"Model: \"+model_name+\"\\n\"+\"Training scores for data split 1 - 5:\")\n",
    "\n",
    "            train_splits_error = \"\"\n",
    "\n",
    "            for i, metric in enumerate(metric_names):\n",
    "                error_value = res[\"train\"+\"_\"+metric]\n",
    "\n",
    "                if metric.startswith(\"neg\"):\n",
    "                    # Negate the value.\n",
    "                    error_value = -error_value\n",
    "\n",
    "                train_error_metrics = \", \".join([f\"{x:.4f}\" for x in error_value.tolist()]) \n",
    "\n",
    "                train_splits_error += f\"{pretty_metric_names[metric]}: {train_error_metrics}\\n\"\n",
    "\n",
    "                metrics_df.loc[pretty_metric_names[metric], model_name+\" Model \"+\"Train\"] = np.mean(error_value)\n",
    "\n",
    "            print(train_splits_error+\"\\n\"+\"Testing scores for data split 1 - 5:\")\n",
    "\n",
    "            test_splits_error = \"\"\n",
    "\n",
    "            for i, metric in enumerate(metric_names):\n",
    "                error_value = res[\"test\"+\"_\"+metric]\n",
    "\n",
    "                if metric.startswith(\"neg\"):\n",
    "                    # Negate the value.\n",
    "                    error_value = -error_value\n",
    "\n",
    "                test_error_metrics = \", \".join([f\"{x:.4f}\" for x in error_value.tolist()]) \n",
    "\n",
    "                test_splits_error += f\"{pretty_metric_names[metric]}: {test_error_metrics}\\n\"\n",
    "\n",
    "                metrics_df.loc[pretty_metric_names[metric], model_name+\" Model \"+\"Test\"] = np.mean(error_value)\n",
    "\n",
    "            print(test_splits_error+\"\\n\")\n",
    "        \n",
    "        print(\"-\"*50+\"\\n\")\n",
    "\n",
    "    return metrics_df_output_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_output = print_calculated_metrics()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plots for insights about the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PLOT FOR SHOWING DIFFERENT DATA SPLITS FOR THE DIFFERENT STOCKS\n",
    "for ticker in stocks_list:\n",
    "    fig, sub_plots = plt.subplots(n_splits, figsize=(16,20))\n",
    "    fig.set_tight_layout(True)\n",
    "\n",
    "    data = stock_data[ticker]\n",
    "    idx = data.index\n",
    "\n",
    "    tscv = TimeSeriesSplit(n_splits=n_splits)\n",
    "\n",
    "    splits = list(tscv.split(data))\n",
    "        \n",
    "    current_split = 1\n",
    "    for i in range(len(sub_plots)):\n",
    "        train_index, test_index = splits[i]\n",
    "\n",
    "        sub_plots[i].plot(idx[train_index], data.loc[idx[train_index], main_col], label=f\"Training data {current_split}\", color=\"blue\")\n",
    "        sub_plots[i].plot(idx[test_index], data.loc[idx[test_index], main_col], label=f\"Test data {current_split}\", color=\"red\")\n",
    "        sub_plots[i].set_xlim(idx[0], idx[-1])\n",
    "        sub_plots[i].set_title(f\"Train / test split {current_split} for {ticker}\")\n",
    "        sub_plots[i].set_xlabel(\"Date\")\n",
    "        sub_plots[i].set_ylabel(f\"{main_col}\")\n",
    "        sub_plots[i].legend()\n",
    "\n",
    "        current_split = current_split + 1\n",
    "    \n",
    "    #fig.savefig(\"data_splits_plots/\"+ticker+\".png\")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PLOT FOR COMPARING ACTUAL TO THE DIFFERENT MODELS PREDICTED VALUES\n",
    "# Created a new list excluding XGBoost, ADA, GBR and Bagging (These are based on DTR).\n",
    "models_for_plot = [\"LR\", \"DTR\", \"MLP\", \"XGBoost_LR\", \"ADA_LR\", \"Bagging_LR\", \"Bagging_MLP\", \"StackedRegressor\"]\n",
    "for ticker, data in stock_data.items():\n",
    "    figure, axs = plt.subplots(figsize=(32,16))\n",
    "    \n",
    "    X, y = create_X_y_arrays(data=data, label_name=\"Label\")\n",
    "    X_train, X_test, y_train, y_test = create_X_y_train_test_split(X=X, y=y, current_stock=ticker)\n",
    "\n",
    "    X_test_index = np.arange(X_train.shape[0], X_train.shape[0]+X_test.shape[0])\n",
    "\n",
    "    plt.plot(data.index[X_test_index], y_test, color='purple', label='Actual', linewidth=\"4.0\")\n",
    "    for model in models_for_plot:\n",
    "        plt.plot(data.index[X_test_index], stock_predictions[ticker][model+\" Prediction\"], label=model)\n",
    "    plt.title(f'Actual vs Predicted, {ticker}')\n",
    "    plt.xlabel('Date')\n",
    "    plt.ylabel('Price')\n",
    "    plt.legend()\n",
    "\n",
    "    #plt.savefig(\"actual_predicted_plots/\"+ticker+\".png\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CORRELATION PLOT BETWEEN THE DIFFERENT STOCKS\n",
    "adj_close_prices = pd.DataFrame({i: j[main_col] for i, j in stock_data.items()})\n",
    "\n",
    "corr = adj_close_prices.corr()\n",
    "\n",
    "sns.heatmap(corr, cmap=\"coolwarm\", annot=True)\n",
    "\n",
    "plt.title(\"Correlation between stocks\")\n",
    "\n",
    "#plt.savefig(\"correlation_plots/correlation_stocks.png\")\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for ticker in stocks_list:\n",
    "#    metrics_output[ticker].to_csv(\"saved_metrics/stock_\"+ticker+\".csv\")\n",
    "#    stock_data[ticker].to_pickle(\"saved_data_pickle/stock_\"+ticker+\".pkl\")\n",
    "#    predicted_stock_data[ticker].to_csv(\"saved_predictions/predicted_data_\"+ticker+\".csv\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grid search to try and find optimal parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "for ticker, data in stock_data.items():\n",
    "    if ticker == \"DNB.OL\": # Manually switch ticker\n",
    "        X, y = create_X_y_arrays(data=data, label_name= \"Label\")\n",
    "        X_train, X_test, y_train, y_test = create_X_y_train_test_split(X=X, y=y, current_stock=ticker)\n",
    "\n",
    "\n",
    "param_grid = {\n",
    "    'criterion': [\"squared_error\", \"friedman_mse\", \"absolute_error\", \"poisson\"],\n",
    "    'max_depth': [1,2,3,4,5,6,7,8,9,10,15,20,50,75,100,250,500,750,1000],\n",
    "    'splitter': [\"best\", \"random\"],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'max_features': [\"auto\", \"sqrt\", \"log2\"],\n",
    "    'random_state': [None, 42]\n",
    "}\n",
    "\n",
    "# TESTED MAINLY ON DTR AND ENSEMBLE METHODS.\n",
    "grid_search = GridSearchCV(estimator=exam_models.DTR(), param_grid=param_grid, cv=tscv)\n",
    "\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Print the best parameters and score\n",
    "print(\"Best parameters: \", grid_search.best_params_)\n",
    "print(\"Best score: \", grid_search.best_score_)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.11 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
